{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nprimavera/Robot-Learning/blob/main/Copy_of_mecs6616_Spring2025_Project1_ncp2136.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWQ_IlDBDxK2"
      },
      "source": [
        "# **MECS6616 Spring 2025 - Project 1**\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on62OZpXBKKZ"
      },
      "source": [
        "# **Introduction**\n",
        "\n",
        "***IMPORTANT:***\n",
        "- **Before starting, make sure to read the [Assignment Instructions](https://courseworks2.columbia.edu/courses/197115/pages/assignment-instructions) page on Courseworks to understand the workflow and submission requirements for this project.**\n",
        "\n",
        "\n",
        "This project applies classical machine learning techniques within a robotics context. Specifically, you will develop a navigation agent designed to maneuver through a simple 2D maze environment.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://drive.google.com/uc?id=1mSpegY1psdek3Lgh6cxzcCGUCF-lddnV\" width=\"300\"/>\n",
        "</div>\n",
        "\n",
        "The figure above illustrates the simulation world, where the \"robot\" (also referred to as \"agent\") is represented by a green dot, and the goal location is marked by a red square. The agent's objective is to navigate to this goal location, avoiding any obstacles (depicted as black boxes) along the way.\n",
        "\n",
        "To navigate to the goal location, the agent will learn appropriate behaviors by imitating demonstrations from an expert user. These demonstrations have been collected in advance by a human controlling the agent via a keyboard. These demonstrations will be provided to you as training data.\n",
        "\n",
        "For this project, we explicitly prohibit the use of Deep Learning and Reinforcement Learning techniques. Instead, we will focus on \"traditional\" supervised learning methods. In future projects, where we will employ DL and RL, we will have the opportunity to understand and appreciate the significant advantages they offer over traditional methods.\n",
        "\n",
        "You should use the scikit-learn library to implement learning algorithms in this project. Comprehensive documentation on its general usage and individual functions can be found on the [scikit-learn page](https://scikit-learn.org/stable/).\n",
        "\n",
        "This project has 3 parts. The instructions for each part are detailed below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfv6pTUGEm90"
      },
      "source": [
        "# **Project Setup (do NOT change)**\n",
        "\n",
        "\n",
        "***IMPORTANT:***\n",
        "- Do NOT change this \"*Project Setup*\" section\n",
        "- Do NOT install any other dependencies or a different version of an already provided package. You may, however, import other packages. Note that scikit-learn is already installed in Colab\n",
        "- Your code should go under the subsequent sections with headings \"*Part 1*\", \"*Part 2*\", and \"*Part 3*\"\n",
        "- The \"*Testing*\" section allows you to test your code's performance using an autograder\n",
        "- You may find it useful to minimize sections using the arrows located to the left of each section heading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ9gCqN944fa"
      },
      "source": [
        "You will be accessing data files located in a class github repo. The following cell clones the repo into the working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYtdJaVWOMER",
        "outputId": "450bcae2-c393-4122-ade1-f72fb6de8e86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'robot-learning-S2024'...\n",
            "remote: Enumerating objects: 63, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 63 (delta 9), reused 57 (delta 7), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (63/63), 625.84 KiB | 2.64 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n"
          ]
        }
      ],
      "source": [
        "# do NOT change\n",
        "\n",
        "# This cell should take less than a minute to run.\n",
        "# After running this cell, the folder 'robot-learning-S2024' will show up in the file explorer on the left\n",
        "# Click on the folder icon if it's not open. Refresh the 'File' page if you still don't see any new files\n",
        "!git clone https://github.com/roamlab/robot-learning-S2024.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emXMmFbVBKV1",
        "outputId": "62400f9b-e37a-46f5-9525-0e73b8ac27c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/robot-learning-S2024/project1/data' -> '/content/data'\n",
            "'/content/robot-learning-S2024/project1/data/bc_with_gtpos_data.pkl' -> '/content/data/bc_with_gtpos_data.pkl'\n",
            "'/content/robot-learning-S2024/project1/data/reg_test_data.pkl' -> '/content/data/reg_test_data.pkl'\n",
            "'/content/robot-learning-S2024/project1/data/regression_data.pkl' -> '/content/data/regression_data.pkl'\n",
            "'/content/robot-learning-S2024/project1/data/bc_data.pkl' -> '/content/data/bc_data.pkl'\n",
            "'/content/robot-learning-S2024/project1/data_utils.py' -> '/content/data_utils.py'\n",
            "'/content/robot-learning-S2024/project1/mjcf' -> '/content/mjcf'\n",
            "'/content/robot-learning-S2024/project1/mjcf/common' -> '/content/mjcf/common'\n",
            "'/content/robot-learning-S2024/project1/mjcf/common/materials.xml' -> '/content/mjcf/common/materials.xml'\n",
            "'/content/robot-learning-S2024/project1/mjcf/common/skybox.xml' -> '/content/mjcf/common/skybox.xml'\n",
            "'/content/robot-learning-S2024/project1/mjcf/common/visual.xml' -> '/content/mjcf/common/visual.xml'\n",
            "'/content/robot-learning-S2024/project1/mjcf/point_mass.xml' -> '/content/mjcf/point_mass.xml'\n",
            "'/content/robot-learning-S2024/project1/mjcf/test_mjcf.xml' -> '/content/mjcf/test_mjcf.xml'\n",
            "'/content/robot-learning-S2024/project1/score_policy.py' -> '/content/score_policy.py'\n",
            "'/content/robot-learning-S2024/project1/simple_maze.py' -> '/content/simple_maze.py'\n"
          ]
        }
      ],
      "source": [
        "# do NOT change\n",
        "\n",
        "# Copy the files needed for project 1 into the current working directory. This is simply to make accessing files easier\n",
        "!cp -av /content/robot-learning-S2024/project1/* /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6p0k4jBuVNQQ",
        "outputId": "c6aefe1e-62f4-403b-d31f-723c875dde9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pybullet\n",
            "  Downloading pybullet-3.2.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Downloading pybullet-3.2.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (103.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pybullet\n",
            "Successfully installed pybullet-3.2.7\n"
          ]
        }
      ],
      "source": [
        "# do NOT change\n",
        "\n",
        "# Installing pybullet, the physics engine that we will use for simulation\n",
        "!pip install pybullet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQjO4d-A7YfO",
        "outputId": "b2c6a6e1-e54a-4ddb-9cf2-cf256b29bc1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpngw\n",
            "  Downloading numpngw-0.1.4-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from numpngw) (1.26.4)\n",
            "Downloading numpngw-0.1.4-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: numpngw\n",
            "Successfully installed numpngw-0.1.4\n"
          ]
        }
      ],
      "source": [
        "# do NOT change\n",
        "\n",
        "# Installing numpngw for visualization\n",
        "!pip3 install numpngw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6kijhsXNoaw"
      },
      "source": [
        "# Part 1. Inferring the Position of an Agent with RGB Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbsQ79WoHU9C"
      },
      "source": [
        "<div>\n",
        "<img src=\"https://drive.google.com/uc?id=1Cn2sAcz0sOXX5x1dvRCEtKCL5yJDYkKS\" width=\"300\"/>\n",
        "</div>\n",
        "\n",
        "\n",
        "Your first task is learning to predict the agent's location within the maze using RGB image observations, such as the one shown above. Each such observation is an RGB image with dimensions $[64, 64]$ for each color channel, resulting in an overall shape of $[64, 64, 3]$ per observation.\n",
        "\n",
        "The maze has its own coordinate system, which you will use to express the agent's location. You will be provided with RGB image observations from this environment, along with the corresponding ground truth location of the agent, expressed in the maze's coordinate system.\n",
        "\n",
        "The task is to develop a model capable of predicting the agent's location based on these RGB observations. Note that this can be seen as a regression problem (if the location of the agent is a continuous variable) or a classification problem (if we discretize the output space to a finite number of possible locations).\n",
        "\n",
        "In this part, you will need to implement the class *PositionRegressor*. Your class will contain two methods:\n",
        "- *train()*: trains a position regressor using the given data\n",
        "- *predict()*: predicts the agent's locations given a batch of observations\n",
        "\n",
        "We will test the performance of your model in this part using the Mean Square Error (MSE) between the predicted positions and the actual (ground truth) positions. We will evaluate your implementation on both the training data (which your model will be trained on) and additional testing data that is held out. Your score will be $$\\text{score} = 1 - MSE$$ and then clipped between 0 and 1.\n",
        "\n",
        "Please implement your solution below by completing the two methods for the *PositionRegressor* class. Note that the actual training and prediction occur in the *Testing* section, where our scoring code loads the data from a file and calls your functions, passing them the appropriate arguments. In *Part 1* (and the subsequent *Part 2* & *Part 3*), you are only required to complete the methods. You do not need to load data and perform training & prediction.\n",
        "\n",
        "We have provided dummy solutions for all three parts of this assignment. This ensures that the scoring function in the *Testing* section can be executed successfully, even if you have completed only a portion of this assignment. If you would like to test your *train()* and *predict()* methods while you're working on it, simply run the code for all three parts, and run the *score_all_parts()* function in the *Testing* section. This will run your *train()* and *predict()* methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uJdME_SVNnRK"
      },
      "outputs": [],
      "source": [
        "# Part 1\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "class PositionRegressor():\n",
        "\n",
        "    \"\"\"\n",
        "    Inferring the Position of an Agent with RGB Images\n",
        "      - learn how to predict the agent's location within the maze using RGB image observations\n",
        "      - each observation is an RGB image with dimensions [64, 64] for each color channel, resulting in an overall shape of [64, 64, 3] per observation\n",
        "      - the maze has its own coordinate system, which you will use to express the agent's location\n",
        "      - can be seen as a regression or classification problem:\n",
        "        - regression problem (if the location of the agent is a continuous variable)\n",
        "        - classification problem (if we discretize the output space to a finite number of possible locations)\n",
        "    \"\"\"\n",
        "\n",
        "    def train(self, data):\n",
        "        \"\"\"\n",
        "        A method that trains a regressor using the given data\n",
        "        Args:\n",
        "            data: a dictionary that contains images and the corresponding ground truth location of an agent.\n",
        "        Returns:\n",
        "            Nothing\n",
        "        \"\"\"\n",
        "\n",
        "        print('\\n\\nPart 1: Position Regressor\\n')\n",
        "        print('\\nTraining model...\\n')\n",
        "\n",
        "        # Initialize the observations (x-values) and agent positions (y-values) - data used for supervised learning\n",
        "        self.X = data['obs'] # observations\n",
        "        self.Y = np.asarray([info['agent_pos'] for info in data['info']])  # agent positions\n",
        "\n",
        "        # Reshape the x-values - LinearRegression expects a 2D array where [rows = samples] , [columns = features]\n",
        "        self.X_reshaped = self.X.reshape(-1, 64*64*3)\n",
        "        self.X_reshaped2 = self.X.reshape(self.X.shape[0], -1) # both work\n",
        "\n",
        "        # Print the data set\n",
        "        #print(\"\\nData used for supervised learning:\")\n",
        "        #print(f'\\nX values (observations):\\n \\n{X}\\n')\n",
        "        #print(f'\\nY values (agent positions):\\n \\n{Y}\\n')\n",
        "        #print(f'\\nX values after being reshaped:\\n \\n{X_reshaped}\\n')\n",
        "\n",
        "        # Data structure shapes\n",
        "        print(f'\\nShape of observation data (X-values): {self.X.shape}')\n",
        "        print(f'Shape of agent position data (Y-values): {self.Y.shape}')\n",
        "        print(f'Shape of observation data (X-values) after being reshaped: {self.X_reshaped.shape}\\n')\n",
        "        #print(f'Shape of observation data (X-values) after being reshaped: {self.X_reshaped2.shape}\\n')\n",
        "\n",
        "        # Model (Linear Regression)\n",
        "        self.model = LinearRegression()  # Linear Regression Model\n",
        "\n",
        "        # Split the data set into testing and training data\n",
        "        self.X_train, self.X_test, self.Y_train, self.Y_test = train_test_split(self.X_reshaped, self.Y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Train the model\n",
        "        self.model.fit(self.X_train, self.Y_train)\n",
        "\n",
        "        print(\"\\nModel training complete.\\n\")\n",
        "\n",
        "        # Evaluate performance on training data\n",
        "        self.Y_train_pred = self.model.predict(self.X_train)\n",
        "\n",
        "        # Calculate Mean Squared Error (MSE)\n",
        "        mse = mean_squared_error(self.Y_train, self.Y_train_pred)\n",
        "        print(f\"\\nTraining MSE: {mse}\")\n",
        "\n",
        "        # Calculate R-squared (R²)\n",
        "        r2 = r2_score(self.Y_train, self.Y_train_pred)\n",
        "        print(f\"Training R²: {r2}\\n\")\n",
        "\n",
        "    def predict(self, Xs):  # Predicts the agent's locations given a batch of observations\n",
        "\n",
        "        \"\"\"\n",
        "        A method that predicts y's given a batch of X's\n",
        "        Args:\n",
        "            Xs: a batch of data (in this project, it is in the shape [batch_size, 64, 64, 3])\n",
        "        Returns:\n",
        "            The predicted locations (y's) of the agent from your trained model. Note that this method expects batched inputs and returns batched outputs\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO\n",
        "\n",
        "        print('\\nPredicting model...\\n')\n",
        "\n",
        "        # Reshape Args (Xs) to comply with Linear Regression model (2D array)\n",
        "        self.Xs_reshaped = Xs.reshape(Xs.shape[0], -1)\n",
        "\n",
        "        # Print data\n",
        "        #print(f'\\nXs values:\\n \\n{Xs}\\n')\n",
        "        #print(f'\\nXs values after being reshaped:\\n \\n{Xs_reshaped}\\n')\n",
        "\n",
        "        # Data structure (shape)\n",
        "        print(f'\\nShape of observation data (Xs): {Xs.shape}')\n",
        "        print(f'Shape of observation data (Xs) after being reshaped: {self.Xs_reshaped.shape}\\n')\n",
        "\n",
        "        # Predict locations (y's) of the agent using the Linear Regression Model\n",
        "        self.y_pred = self.model.predict(self.Xs_reshaped)\n",
        "\n",
        "        print('\\nModel prediction complete.\\n')\n",
        "\n",
        "        return self.y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POFHlL1xNx8s"
      },
      "source": [
        "# Part 2. Behavioral Cloning with Low Dimensional Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW80lZu0Jr1e"
      },
      "source": [
        "In *Part 2*, your task is to develop a model that decides the agent's next action based on environmental observations. The agent has three possible actions: moving up, left, or right. The objective is to navigate the agent towards the goal square, which is marked in red in the figures provided above.\n",
        "\n",
        "Note that, in general terms, what you are providing here is a \"policy\" - a model that selects an action based on observations from the world. There are various methods for training such policies, and we will explore many of these techniques in the Reinforcement Learning section of the course.\n",
        "\n",
        "It is important to note that learning a policy can also be approached as a Supervised Learning problem. In this scenario, you will receive labeled examples from an \"expert\". Each example will include a tuple in the form of $(o, a)_i$, where $o$ denotes an observation and $a$ indicates the action taken by the expert in response to that observation. You must simply learn to imitate the expert, a process also known as behavioral cloning. If the action space is discrete, behavioral cloning becomes a classification problem; if it's continuous, it turns into a regression problem. We will be working on an environment that has a discrete action space. Consequently, we can treat behavioral cloning as a classification problem with three output classes: go up, go left, and go right.\n",
        "\n",
        "In *Part 2*, the observation will be the agent's ground truth position within the maze's coordinate system. The training data will consist of tuples $(o, a)_i$  where $o$ represents the agent's location in the maze, and $a$ is the action taken by the expert at that location. You may use any classification method from Scikit-learn to learn the mapping from these observations to the corresponding actions.\n",
        "\n",
        "You will need to implement the class *POSBCRobot()*. The methods to implement are documented below. We will evaluate your model by having the robot execute the commands generated by your policy, or in other words, by \"rolling out your policy\" in the environment. After 20 steps, we will compute how close the robot gets to the goal. Formally, the score for a single run will be calculated based on the minimum distance between your agent and the target location achieved over a trajectory of 100 steps. We will run your agent 20 times in the environment and use the following formula to calculate your score:\n",
        "\n",
        "$$\\text{score} = \\frac{(∑^{20}_n(\\text{init_dist - min_dist}_n))/20}{\\text{init_dist}}$$\n",
        "\n",
        "Essentially, you will be scored on the average performance across all 20 runs, meaning consistency is an important part of performance.\n",
        "\n",
        "Similar to *Part 1*, you are only required to complete the methods. Our scoring function will load the data and test your implementations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OfTObQ5hN0gp"
      },
      "outputs": [],
      "source": [
        "# Part 2\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import plot_tree\n",
        "\n",
        "class POSBCRobot():\n",
        "\n",
        "    \"\"\"\n",
        "    Behavioral Cloning with Low Dimensional Data\n",
        "      - model decides the agent's next action based on environmental observations\n",
        "      - agent has 3 possible actions: moving up, left or right (0, 1, or 2)\n",
        "      - this is called a \"policy\" - a model that selects an action based on observations from the world\n",
        "        - can be approached using RL or Supervised Learning\n",
        "          - Using Supervised Learning\n",
        "            - receive labeled examples from an \"expert\" in the form of a tuple (o,a)_i - o=observation, a=action\n",
        "            - the observation will be the agent's ground truth position within the maze's coordinate system\n",
        "            - o represents the agent's location in the maze and a is the action taken by the expert at that location\n",
        "            - learn to imitate the \"expert\" --> Behavioral Cloning\n",
        "            - if the action space is discrete, behavioral cloning becomes a classification problem\n",
        "            - if the action space is continuous, it turns into a regression problem\n",
        "\n",
        "    Classification vs. Regression Problem\n",
        "      - Behavioral Cloning --> Action Space = Discrete --> Classification Problem --> 3 output classes (go up, go left, go right)\n",
        "      - Behavioral Cloning --> Action Space = Continuous --> Regression Problem --> 3 output classes (go up, go left, go right)\n",
        "\n",
        "    Behavioral Cloning - learning from expert demonstrations\n",
        "\n",
        "    Classification - predicting actions from observations (behavioral cloning)\n",
        "\n",
        "    Regression - predicting continuous values (position) from observations\n",
        "    \"\"\"\n",
        "\n",
        "    def train(self, data):\n",
        "\n",
        "        \"\"\"\n",
        "        A method for training a policy.\n",
        "        Args:\n",
        "            data: a dictionary that contains X (observations) and y (actions).\n",
        "        Returns:\n",
        "            This method does not return anything. It only need to update the property of a RobotPolicy instance.\n",
        "        \"\"\"\n",
        "\n",
        "        print('Part 2: Behavioral Cloning with Low Dimensional Data\\n')\n",
        "        print('\\nTraining the \"policy\"...\\n')\n",
        "\n",
        "        # Data is a dictionary with 'obs' and 'actions' keys - convert dictionary data into feature matrix (X) and labels (y)\n",
        "        #print(f\"\\nData set:\\n \\n{data}\\n\")   # check\n",
        "        self.X = np.array(data.get('obs', []))         # Extract observations\n",
        "        self.Y = np.array(data.get('actions', []))     # Extract actions - column vector\n",
        "        self.Y_reshaped = np.array(data.get('actions', [])).reshape(-1)   # Ensure it's a 1D array\n",
        "\n",
        "        # Print the data set\n",
        "        #print(type(data['obs']), type(data['actions']))\n",
        "        #print(f\"\\nSample X (observations):\\n \\n{data['obs'][:5]}\\n\") # first 5 points\n",
        "        #print(f\"\\nSample Y (actions):\\n \\n{data['actions'][:5]}\\n\")  #   \"   \"   \"\n",
        "\n",
        "        # Data structure shapes\n",
        "        print(f'\\nX values shape: {self.X.shape}')  # Should be (500, 2)\n",
        "        print(f'Y values shape: {self.Y.shape}')    # Should be (500, 1) before reshape - column vector\n",
        "        print(f'Y_reshaped values shape: {self.Y_reshaped.shape}')  # Should be (500,) - need a 1D array instead of a columns vector\n",
        "\n",
        "        # Standardize X values - improves results\n",
        "        self.scaler = StandardScaler()\n",
        "        self.X_scaled = self.scaler.fit_transform(self.X)\n",
        "        print(f'X_scaled shape: {self.X_scaled.shape}')\n",
        "\n",
        "        # Normalization - worsens results\n",
        "        #self.scaler = MinMaxScaler()\n",
        "        #self.X_normalized = self.scaler.fit_transform(self.X)\n",
        "        #print(f'\\nX_normalized shape: {self.X_normalized.shape}\\n')\n",
        "\n",
        "        # PCA - makes model performance worse\n",
        "        #self.pca = PCA(n_components=2) # Dimensionality Reduction\n",
        "        #self.X_pca = self.pca.fit_transform(self.X_scaled)\n",
        "        #print(f'X_pca shape: {self.X_pca.shape}')\n",
        "\n",
        "        # Split the data set into testing and training data\n",
        "        self.X_train, self.X_test, self.Y_train, self.Y_test = train_test_split(self.X_scaled, self.Y_reshaped, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Model (Random Forest classifier)\n",
        "        self.classification = RandomForestClassifier(n_estimators=100, max_depth=10, max_features='sqrt', min_samples_leaf=1, min_samples_split=2, random_state=42)\n",
        "\n",
        "        # Train the model\n",
        "        self.classification.fit(self.X_train, self.Y_train)\n",
        "\n",
        "        # Hyperparameters\n",
        "        #self.classification = RandomForestClassifier(random_state=42)\n",
        "        #print(\"\\nSolving hyperparameter grid.\")\n",
        "        #param_grid = {\n",
        "            #'n_estimators': [1, 20, 50, 100, 150, 200],\n",
        "            #'max_depth': [5, 10, None],\n",
        "            #'min_samples_split': [2, 5, 10, 15],\n",
        "            #'min_samples_leaf': [1, 2, 4, 5],\n",
        "            #'max_features': ['sqrt', 'log2']\n",
        "        #}\n",
        "        #grid_search = GridSearchCV(self.classification, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "        #grid_search = GridSearchCV(self.classification, param_grid, cv=5, scoring='accuracy', n_jobs=-1) # Grid Search\n",
        "        #grid_search.fit(self.X_train, self.Y_train)  # train the model\n",
        "        #self.classification = grid_search.best_estimator_  # Best model\n",
        "        #print(\"\\nBest Parameters:\", grid_search.best_params_)  # Best parameters\n",
        "\n",
        "        # Visualize\n",
        "        #print(f\"\\nRandom Forest:\\n\\n\")\n",
        "        #plt.figure(figsize=(12,8))\n",
        "        #plot_tree(self.classification.estimators_[0], filled=True, feature_names=[\"Feature 1\", \"Feature 2\"])\n",
        "        #plt.show()\n",
        "\n",
        "        print(\"\\nPolicy training complete.\\n\")\n",
        "\n",
        "        # Check model performance\n",
        "        train_preds = self.classification.predict(self.X_train)\n",
        "        test_preds = self.classification.predict(self.X_test)\n",
        "        print(f\"\\nTrain Accuracy: {accuracy_score(self.Y_train, train_preds)}\")\n",
        "        print(f\"Test Accuracy: {accuracy_score(self.Y_test, test_preds)}\")\n",
        "        print(f\"Classification report:\\n \\n{classification_report(self.Y_test, test_preds)}\\n\")\n",
        "\n",
        "        # Add confusion matrix to see which actions the model has trouble with\n",
        "        def plot_confusion_matrix(y_true, y_pred):\n",
        "            cm = confusion_matrix(y_true, y_pred)\n",
        "            plt.figure(figsize=(6,5))\n",
        "            sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Up', 'Left', 'Right'], yticklabels=['Up', 'Left', 'Right'])\n",
        "            plt.xlabel('Predicted')\n",
        "            plt.ylabel('Actual')\n",
        "            plt.title('Confusion Matrix')\n",
        "            plt.show()\n",
        "        plot_confusion_matrix(self.Y_test, test_preds)\n",
        "\n",
        "    def get_actions(self, observations):\n",
        "\n",
        "        \"\"\"\n",
        "        A method for getting actions. You can do data preprocessing and feed forward of your trained model here.\n",
        "        Args:\n",
        "            observations: a batch of observations (images or vectors)\n",
        "        Returns:\n",
        "            A batch of actions with the same batch size as observations.\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO\n",
        "\n",
        "        #print('\\nGetting actions\"...\\n') # prints too much\n",
        "\n",
        "        # Check\n",
        "        #print(f'\\nObservations shape: {observations.shape}\\n')  # should be (1, 2)\n",
        "\n",
        "        self.observations = np.array(observations) # observations\n",
        "\n",
        "        # Reshape observations - lowered score\n",
        "        #self.observations_reshaped = np.array(observations).reshape(-1, self.X.shape[1])  # Ensure 2D input\n",
        "        #print(f'\\nObservatiosn reshaped shape: {observations_reshaped.shape}\\n')  # should be (1, 2)\n",
        "\n",
        "        # Scale observations - lowered score\n",
        "        #self.observations_scaled = self.scaler.transform(self.observations_reshaped)\n",
        "        #print(f'\\nObservations scaled shape: {observations_scaled.shape}\\n')  # should be (1, 2)\n",
        "\n",
        "        # PCA - lowered score\n",
        "        #self.observations_pca = self.pca.transform(self.observations_reshaped)\n",
        "        #self.observations_pca = self.pca.transform(self.observations_scaled)\n",
        "        #print(f'\\nObservations PCA shape: {self.observations_pca.shape}\\n')  # should be (1, 2)\n",
        "\n",
        "        # Use the Classification model to predict actions based on the observations\n",
        "        self.actions = self.classification.predict(self.observations) # 1D array\n",
        "\n",
        "        return self.actions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRtN8RuwN0zS"
      },
      "source": [
        "# Part 3. Behavioral cloning with visual observations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub_ejt1bL9NC"
      },
      "source": [
        "In *Part 3*, you are asked to do a similar task as *Part 2*, but the observations will be a lot more challenging to use. Rather than using the actual (ground truth) location of the agent (robot), your model will receive as input RGB image observations of the world, similar to the ones you used to perform localization in *Part 1*.\n",
        "\n",
        "You will need to implement the class RGBBCRobot(). All requirements for your code, as well as the evaluation method, remain unchanged from *Part 2*. The only difference is the nature of the observation that is provided to you. Once again, you are only required to complete the methods. Our scoring function will load the data and test your implementations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "9trpNkL8N3Di"
      },
      "outputs": [],
      "source": [
        "# Part 3\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "\n",
        "class RGBBCRobot():\n",
        "\n",
        "    \"\"\"\n",
        "    Behavioral Cloning with Visual Observations\n",
        "      - model decides the agent's next action based on environmental observations\n",
        "      - instead of using the actual location (ground truth), the model will receive as input RGB image observations of the world\n",
        "      - observation will be a RGB image with dimensions [64, 64, 3]\n",
        "\n",
        "    RGB Images:\n",
        "      - visual inputs represented as images w/ 3 color channels Red, Green, Blue\n",
        "      - each pixel in the image consists of 3 values corresponding to the intensity of the 3 primary colors\n",
        "      - model/agent learning from visual data\n",
        "      - shape: [height, weight, 3], where 3 is the number of color channels (RGB)\n",
        "      - pixel values range: [0, 255] - integer values in raw images & [0, 1] - normalized for deep learning\n",
        "    \"\"\"\n",
        "\n",
        "    # Bag of Features Image Classifications\n",
        "    def __init__(self, n_clusters=50):\n",
        "        self.n_clusters = n_clusters  # Number of clusters for K-Means\n",
        "        self.scaler = StandardScaler()\n",
        "        self.kmeans = KMeans(n_clusters=n_clusters, random_state=42, init='k-means++', n_init=10)\n",
        "        #self.gbm = GradientBoostingClassifier(n_estimators=100, learning_rate=00.1, max_depth=3, subsample=0.8,\n",
        "                                             #min_samples_split=5, min_samples_leaf=2, random_state=42)\n",
        "        #self.kmeans = KMeans()\n",
        "        self.gbm = GradientBoostingClassifier()\n",
        "        self.svm = SVC(probability=True)\n",
        "        self.vocabulary = None\n",
        "\n",
        "    def extract_patches_and_create_vocabulary(self, observations):\n",
        "\n",
        "        print(\"\\nExtracting keypoints/patches from images and clusters them into a visual vocabulary using Kmeans.\")\n",
        "        print(\"The observations data set is a batch of observations (images or vectors).\\n\")\n",
        "\n",
        "        # Create a SIFT detector object\n",
        "        sift = cv2.SIFT_create()\n",
        "\n",
        "        # List to store descriptors of keypoints from all images\n",
        "        descriptors_list = []\n",
        "\n",
        "        # Loop through each observation (image) to detect keypoints and compute descriptors\n",
        "        for image in observations:\n",
        "            keypoints, descriptors = sift.detectAndCompute(image, None)\n",
        "            if descriptors is not None:\n",
        "                descriptors_list.append(descriptors)  # if descriptors exist, add them\n",
        "\n",
        "        # Stack all the descriptors into a single array\n",
        "        descriptors_stack = np.vstack(descriptors_list)\n",
        "\n",
        "        # Kmeans clustering\n",
        "        self.kmeans.fit(descriptors_stack)\n",
        "\n",
        "        # Set the cluster centers as the visual vocabulary\n",
        "        self.vocabulary = self.kmeans.cluster_centers_\n",
        "\n",
        "        #print(f\"\\nVocabulary size: {self.vocabulary.shape}\") # error handling\n",
        "        #print(f\"Vocabulary:\\n \\n{self.vocabulary}\\n\")\n",
        "        #print(f\"\\nImage:\\n \\n{image}\\n\")\n",
        "        #print(f\"\\nObservations:\\n \\n{observations}\\n\")\n",
        "\n",
        "    def image_to_feature_histogram(self, image):  # image to feature\n",
        "\n",
        "        \"\"\" Converts an image into a histogram of visual words. \"\"\"\n",
        "\n",
        "        # Create a SIFT detector object\n",
        "        sift = cv2.SIFT_create()\n",
        "\n",
        "        # Detect keypoints and compute descriptors in the image\n",
        "        keypoints, descriptors = sift.detectAndCompute(image, None)\n",
        "\n",
        "        # Return a 0 histogram if there are no descriptors\n",
        "        if descriptors is None:\n",
        "            return np.zeros(self.n_clusters)  # no visual features\n",
        "\n",
        "        # Predict the closest cluster (visual world) for each descriptor\n",
        "        labels = self.kmeans.predict(descriptors) # using Kmeans\n",
        "\n",
        "        # Compute a normalized histogram of labels (visual worlds) where each bn corresponds to a visual world from vocabulary\n",
        "        histogram, _ = np.histogram(labels, bins=np.arange(self.n_clusters + 1), density=True)\n",
        "\n",
        "        # Error handling\n",
        "        #print(f\"\\nDescriptors shape: {descriptors.shape}\")\n",
        "        #print(f\"Descriptors:\\n \\n{descriptors}\\n\")\n",
        "        #print(f\"\\nLabels shape: {labels.shape}\")\n",
        "        #print(f\"Labels:\\n \\n{labels}\\n\")\n",
        "        #print(f\"\\nHistogram shape: {histogram.shape}\")\n",
        "        #print(f\"Histogram:\\n \\n{histogram}\\n\")\n",
        "\n",
        "        return histogram\n",
        "\n",
        "    def train(self, data):\n",
        "\n",
        "        \"\"\"\n",
        "        A method for training a policy.\n",
        "        Args:\n",
        "            data: a dictionary that contains X (observations) and y (actions).\n",
        "        Returns:\n",
        "            This method does not return anything. It will just need to update the property of a RobotPolicy instance.\n",
        "        \"\"\"\n",
        "\n",
        "        print('\\n\\nPart 3: Behavioral Cloning with Visual Observations\\n')\n",
        "        print('Training SVM and Gradient Boosting classifiers using extracted histograms...')\n",
        "\n",
        "        # Preliminary code\n",
        "        #print(f\"\\nData:\\n {data}\\n\")\n",
        "\n",
        "        # Data extraction\n",
        "        #images = data.get('obs', [])  # extracting observations (images)\n",
        "        #actions = data.get('actions', []) # extracting actions\n",
        "        images = np.array(data.get('obs', []))  # (num_samples, 64, 64, 3)\n",
        "        actions = np.array(data.get('actions', []))  # column vector (num_samples, 1)\n",
        "        print(\"\\nData Structures:\")\n",
        "        print(f'Images shape: {images.shape}')\n",
        "        print(f'Actions shape: {actions.shape}')\n",
        "\n",
        "        # Data reshaping\n",
        "        actions_reshaped = actions.reshape(-1)  # Convert to 1D\n",
        "        print(\"\\nData Structures after reshaping:\")\n",
        "        print(f'Actions reshaped shape: {actions_reshaped.shape}')\n",
        "\n",
        "        # Check class distribution\n",
        "        counter = Counter(actions_reshaped)\n",
        "        print(\"\\nClass Distribution:\", counter)\n",
        "\n",
        "        # Apply SMOTE (synthetic minority oversampling) only if imbalance is significant - oversample the minority class\n",
        "        #n_samples = images.shape[0]\n",
        "        #images_reshaped = images.reshape(n_samples, -1) # reshape to (n_samples, height * width * channels)\n",
        "        #if min(counter.values()) / max(counter.values()) < 0.5:  # Imbalance threshold\n",
        "            #smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "            #images_reshaped, actions_reshaped = smote.fit_resample(images_reshaped, actions_reshaped)\n",
        "            #new_n_samples = images_reshaped.shape[0]\n",
        "            #images = images_reshaped.reshape(new_n_samples, 64, 64, 3)\n",
        "            ##print(\"\\nApplied SMOTE. Adds synthetic values to balance out the data set.\")\n",
        "            #counter_smote = Counter(actions_reshaped)\n",
        "            #print(\"\\nClass Distribution after SMOTE:\", counter_smote)\n",
        "\n",
        "        # Extract patches and create vocabulary\n",
        "        self.extract_patches_and_create_vocabulary(images)  # Fit KMeans here\n",
        "\n",
        "        # Convert images to feature histograms\n",
        "        feature_histograms = np.array([self.image_to_feature_histogram(image) for image in images])\n",
        "\n",
        "        # Standardization feature histograms values to [0, 1]\n",
        "        feature_histograms = self.scaler.fit_transform(feature_histograms)\n",
        "\n",
        "        # Split data into training and testing sets\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(feature_histograms, actions_reshaped, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Compute sample weights for class balancing\n",
        "        sample_weights = compute_sample_weight(class_weight=\"balanced\", y=self.y_train)\n",
        "\n",
        "            # Train Gradient Boosting with hyperparameter tuning\n",
        "            #self.GB = GradientBoostingClassifier(random_state=42)\n",
        "            #param_grid = {'n_estimators': [100, 300, 500], 'learning_rate': [0.01, 0.05, 0.1], 'max_depth': [3, 5, 7], 'subsample': [0.8, 0.9, 1.0],\n",
        "                          #'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}\n",
        "            #grid_search = GridSearchCV(estimator=self.GB, param_grid=param_grid, scoring='accuracy', cv=2, n_jobs=-1)#, verbose=2)\n",
        "            #grid_search.fit(self.X_train, self.Y_train) # fit the model\n",
        "            #print(\"Best parameters:\", grid_search.best_params_) # Best parameters and model training\n",
        "            #print(\"Best accuracy:\", grid_search.best_score_)\n",
        "\n",
        "            # Train the best Gradient Boosting model\n",
        "            #self.GB = grid_search.best_estimator_\n",
        "            #self.GB.fit(self.X_train, self.Y_train)\n",
        "\n",
        "            # Evaluate on the test set\n",
        "            #self.Y_pred = self.GB.predict(self.X_test)\n",
        "            #self.accuracy = accuracy_score(self.Y_test, self.Y_pred)\n",
        "            #print(f\"\\nTest Accuracy: {self.accuracy:.4f}\")\n",
        "\n",
        "        # Train the models\n",
        "        self.svm.fit(self.X_train, self.y_train)\n",
        "        self.gbm.fit(self.X_train, self.y_train, sample_weight=sample_weights)\n",
        "\n",
        "        # Evaluate models\n",
        "        #print(\"Evaluating on training data...\\n\")\n",
        "        #self.evaluate(data)\n",
        "        print(\"Evaluating on testing data...\\n\")\n",
        "        self.evaluate((self.X_test, self.y_test))\n",
        "\n",
        "    def get_actions(self, observations):\n",
        "\n",
        "        \"\"\"\n",
        "        A method for getting actions. You can do data preprocessing and feed forward of your trained model here.\n",
        "        Args:\n",
        "            observations: a batch of observations (images or vectors)\n",
        "        Returns:\n",
        "            A batch of actions with the same batch size as observations.\n",
        "        \"\"\"\n",
        "\n",
        "        #print(\"\\nPredicting actions using trained classifiers SVM and GB.\")  # prints too much\n",
        "\n",
        "        feature_histograms = np.array([self.image_to_feature_histogram(image) for image in observations])\n",
        "        feature_histograms = self.scaler.transform(feature_histograms)\n",
        "\n",
        "        # Predict the probabilities using the trained models\n",
        "        self.svm_probs = self.svm.predict_proba(feature_histograms)\n",
        "        self.gbm_probs = self.gbm.predict_proba(feature_histograms)\n",
        "        print(f\"\\nSVM probability: {self.svm_probs}\")\n",
        "        print(f\"Gradient Boosting probability: {self.gbm_probs}\\n\")\n",
        "\n",
        "        # Average the probabilities to get a final prediction\n",
        "        avg_probs = (self.svm_probs + self.gbm_probs) / 2\n",
        "        final_predictions = np.argmax(avg_probs, axis=1)\n",
        "\n",
        "        return final_predictions\n",
        "\n",
        "    def evaluate(self, test_data):\n",
        "\n",
        "        # Unpack the test data into images (X) and true labels (y)\n",
        "        X_test, y_test = test_data\n",
        "\n",
        "        # Predict actions using the trained model\n",
        "        predicted_labels = self.get_actions(X_test)\n",
        "\n",
        "        # Compute accuracy and classification report\n",
        "        accuracy = accuracy_score(y_test, predicted_labels)\n",
        "        report = classification_report(y_test, predicted_labels)\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print(\"Classification Report:\\n\", report)\n",
        "\n",
        "        # Compute confusion matrix\n",
        "        cm = confusion_matrix(y_test, predicted_labels)\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        def plot_confusion_matrix(y_true, y_pred, class_labels):\n",
        "            cm = confusion_matrix(y_true, y_pred)\n",
        "            plt.figure(figsize=(6, 5))\n",
        "            sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Up', 'Left', 'Right'], yticklabels=['Up', 'Left', 'Right'])\n",
        "            plt.xlabel('Predicted')\n",
        "            plt.ylabel('Actual')\n",
        "            plt.title('Confusion Matrix')\n",
        "            plt.show()\n",
        "        class_labels = ['Up', 'Left', 'Right']  # Define class labels based on the dataset\n",
        "        plot_confusion_matrix(y_test, predicted_labels, class_labels)\n",
        "\n",
        "        return accuracy, report, cm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHBv0jRpNgZB"
      },
      "source": [
        "# **Testing**\n",
        "\n",
        "We will use the cells provided below to automatically generate your score for this project. To assess your progress, simply execute these cells.\n",
        "\n",
        "If you wish to visualize your policy, set gui_enable to True. Doing so will create an animated .png file, which you can view using the cell at the end of the notebook. Please note that enabling this visualization may result in longer runtime.\n",
        "\n",
        "\n",
        "**Grading Rubrics**\n",
        "\n",
        "You are graded based on the scores you achieved for each part. Each part is 5 points and the final grade you get for this project is the sum of all points from three parts (thus, 15 maximum in total)\n",
        "\n",
        "**Part 1**\n",
        "\n",
        "- score >= 0.99, you get 5/5\n",
        "- score >= 0.95, you get 4/5\n",
        "- score >= 0.80, you get 2/5\n",
        "\n",
        "**Part 2**\n",
        "\n",
        "- score >= 0.99, you get 5/5\n",
        "- score >= 0.80, you get 3/5\n",
        "\n",
        "**Part 3**\n",
        "\n",
        "- score >= 0.99, you get 5/5\n",
        "- score >= 0.90, you get 4/5\n",
        "- score >= 0.80, you get 3/5\n",
        "- score >= 0.60. you get 2/5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTBR5b_xrDS8"
      },
      "source": [
        "### Turn GUI on/off (you may change) -- **please set to False before submission**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5UOXzIhFrGiq"
      },
      "outputs": [],
      "source": [
        "# Enabling the gui saves animated pngs to the working directory\n",
        "# You can view the pngs using the cell at the bottom of the notebook\n",
        "# Code runs slightly slower when gui is enabled, as pngs need to be generated\n",
        "# Use the gui to debug if you're not sure where it's getting stuck\n",
        "# Or just to see a succesful visualization once you have it working!\n",
        "\n",
        "gui = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRuhidcFQaNv"
      },
      "source": [
        "### Score Policy (do NOT change)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5yxmcyyW4jvj",
        "outputId": "e7830bee-cc2f-4545-f395-bfa4ae56547d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Part 2: Behavioral Cloning with Low Dimensional Data\n",
            "\n",
            "\n",
            "Training the \"policy\"...\n",
            "\n",
            "\n",
            "X values shape: (500, 2)\n",
            "Y values shape: (500, 1)\n",
            "Y_reshaped values shape: (500,)\n",
            "X_scaled shape: (500, 2)\n",
            "\n",
            "Policy training complete.\n",
            "\n",
            "\n",
            "Train Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Classification report:\n",
            " \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        59\n",
            "           1       1.00      1.00      1.00        24\n",
            "           2       1.00      1.00      1.00        17\n",
            "\n",
            "    accuracy                           1.00       100\n",
            "   macro avg       1.00      1.00      1.00       100\n",
            "weighted avg       1.00      1.00      1.00       100\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfkAAAHWCAYAAAB0TPAHAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAP9BJREFUeJzt3XlcVHX7//H3gDAgq+CeC7jhvmZqVi5pamUqlmndBWZl3WopWqZlbhllqS3u9+2NZpqlmZV1a6Ypmctt7lauaVSKO5jbgHB+f/h1fk2gMTowcM7r2eM8Hs7nnDnnOkxwzXXN55yxGYZhCAAAmI6PtwMAAAD5gyQPAIBJkeQBADApkjwAACZFkgcAwKRI8gAAmBRJHgAAkyLJAwBgUiR5AABMiiQP5NG+fft01113KSwsTDabTUuWLPHo/g8dOiSbzabZs2d7dL9FWevWrdW6dWtvhwEUWSR5FCkHDhxQ3759VaVKFQUEBCg0NFQtW7bU22+/rQsXLuTrsePi4rRz506NGzdOc+fO1c0335yvxytI8fHxstlsCg0NzfXnuG/fPtlsNtlsNr355ptu7//w4cMaNWqUtm3b5oFoAeRVMW8HAOTVF198oQceeEB2u12PPvqo6tatq4yMDK1du1bPPfecfvjhB82cOTNfjn3hwgWtX79eL774ovr3758vx6hcubIuXLggPz+/fNn/3ylWrJjOnz+vzz//XD169HBZN2/ePAUEBOjixYvXte/Dhw9r9OjRioqKUsOGDfP8vK+++uq6jgfgMpI8ioSDBw+qZ8+eqly5slatWqVy5co51/Xr10/79+/XF198kW/HP378uCQpPDw8345hs9kUEBCQb/v/O3a7XS1bttQHH3yQI8nPnz9f99xzjz7++OMCieX8+fMqXry4/P39C+R4gFnRrkeRMH78eJ09e1azZs1ySfBXVKtWTc8++6zz8aVLlzR27FhVrVpVdrtdUVFRGj58uBwOh8vzoqKidO+992rt2rW65ZZbFBAQoCpVqui9995zbjNq1ChVrlxZkvTcc8/JZrMpKipK0uU295V//9moUaNks9lcxlasWKHbbrtN4eHhCg4OVkxMjIYPH+5cf7XP5FetWqXbb79dQUFBCg8PV5cuXfTTTz/lerz9+/crPj5e4eHhCgsLU+/evXX+/Pmr/2D/4qGHHtJ///tfpaWlOcc2bdqkffv26aGHHsqx/alTpzRkyBDVq1dPwcHBCg0NVadOnbR9+3bnNqtXr1bTpk0lSb1793a2/a+cZ+vWrVW3bl1t3rxZd9xxh4oXL+78ufz1M/m4uDgFBATkOP8OHTqoRIkSOnz4cJ7PFbACkjyKhM8//1xVqlTRrbfemqftH3/8cb388stq3LixJk2apFatWikxMVE9e/bMse3+/ft1//33q3379powYYJKlCih+Ph4/fDDD5Kk2NhYTZo0SZLUq1cvzZ07V2+99ZZb8f/www+699575XA4NGbMGE2YMEH33Xefvvvuu2s+7+uvv1aHDh107NgxjRo1SgkJCVq3bp1atmypQ4cO5di+R48e+uOPP5SYmKgePXpo9uzZGj16dJ7jjI2Nlc1m0+LFi51j8+fPV82aNdW4ceMc2//8889asmSJ7r33Xk2cOFHPPfecdu7cqVatWjkTbq1atTRmzBhJ0pNPPqm5c+dq7ty5uuOOO5z7OXnypDp16qSGDRvqrbfeUps2bXKN7+2331apUqUUFxenrKwsSdKMGTP01Vdf6d1331X58uXzfK6AJRhAIZeenm5IMrp06ZKn7bdt22ZIMh5//HGX8SFDhhiSjFWrVjnHKleubEgykpOTnWPHjh0z7Ha7MXjwYOfYwYMHDUnGG2+84bLPuLg4o3LlyjliGDlypPHnX69JkyYZkozjx49fNe4rx0hKSnKONWzY0ChdurRx8uRJ59j27dsNHx8f49FHH81xvMcee8xln926dTMiIyOvesw/n0dQUJBhGIZx//33G3feeadhGIaRlZVllC1b1hg9enSuP4OLFy8aWVlZOc7DbrcbY8aMcY5t2rQpx7ld0apVK0OSMX369FzXtWrVymVs+fLlhiTjlVdeMX7++WcjODjY6Nq169+eI2BFVPIo9M6cOSNJCgkJydP2X375pSQpISHBZXzw4MGSlOOz+9q1a+v22293Pi5VqpRiYmL0888/X3fMf3Xls/xPP/1U2dnZeXrOkSNHtG3bNsXHxysiIsI5Xr9+fbVv3955nn/21FNPuTy+/fbbdfLkSefPMC8eeughrV69WqmpqVq1apVSU1NzbdVLlz/H9/G5/GckKytLJ0+edH4UsWXLljwf0263q3fv3nna9q677lLfvn01ZswYxcbGKiAgQDNmzMjzsQArIcmj0AsNDZUk/fHHH3na/pdffpGPj4+qVavmMl62bFmFh4frl19+cRmvVKlSjn2UKFFCp0+fvs6Ic3rwwQfVsmVLPf744ypTpox69uypjz766JoJ/0qcMTExOdbVqlVLJ06c0Llz51zG/3ouJUqUkCS3zuXuu+9WSEiIPvzwQ82bN09NmzbN8bO8Ijs7W5MmTVL16tVlt9tVsmRJlSpVSjt27FB6enqej3nTTTe5NcnuzTffVEREhLZt26Z33nlHpUuXzvNzASshyaPQCw0NVfny5bVr1y63nvfXiW9X4+vrm+u4YRjXfYwrnxdfERgYqOTkZH399dd65JFHtGPHDj344INq3759jm1vxI2cyxV2u12xsbGaM2eOPvnkk6tW8ZL06quvKiEhQXfccYfef/99LV++XCtWrFCdOnXy3LGQLv983LF161YdO3ZMkrRz5063ngtYCUkeRcK9996rAwcOaP369X+7beXKlZWdna19+/a5jB89elRpaWnOmfKeUKJECZeZ6Ff8tVsgST4+Prrzzjs1ceJE/fjjjxo3bpxWrVqlb775Jtd9X4lzz549Odbt3r1bJUuWVFBQ0I2dwFU89NBD2rp1q/74449cJytesWjRIrVp00azZs1Sz549ddddd6ldu3Y5fiZ5fcOVF+fOnVPv3r1Vu3ZtPfnkkxo/frw2bdrksf0DZkKSR5Hw/PPPKygoSI8//riOHj2aY/2BAwf09ttvS7rcbpaUYwb8xIkTJUn33HOPx+KqWrWq0tPTtWPHDufYkSNH9Mknn7hsd+rUqRzPvXJTmL9e1ndFuXLl1LBhQ82ZM8clae7atUtfffWV8zzzQ5s2bTR27FhNnjxZZcuWvep2vr6+OboECxcu1O+//+4yduXNSG5viNw1dOhQpaSkaM6cOZo4caKioqIUFxd31Z8jYGXcDAdFQtWqVTV//nw9+OCDqlWrlssd79atW6eFCxcqPj5ektSgQQPFxcVp5syZSktLU6tWrfS///1Pc+bMUdeuXa96edb16Nmzp4YOHapu3brpmWee0fnz5zVt2jTVqFHDZeLZmDFjlJycrHvuuUeVK1fWsWPHNHXqVFWoUEG33XbbVff/xhtvqFOnTmrRooX69OmjCxcu6N1331VYWJhGjRrlsfP4Kx8fH7300kt/u929996rMWPGqHfv3rr11lu1c+dOzZs3T1WqVHHZrmrVqgoPD9f06dMVEhKioKAgNWvWTNHR0W7FtWrVKk2dOlUjR450XtKXlJSk1q1ba8SIERo/frxb+wNMz8uz+wG37N2713jiiSeMqKgow9/f3wgJCTFatmxpvPvuu8bFixed22VmZhqjR482oqOjDT8/P6NixYrGsGHDXLYxjMuX0N1zzz05jvPXS7eudgmdYRjGV199ZdStW9fw9/c3YmJijPfffz/HJXQrV640unTpYpQvX97w9/c3ypcvb/Tq1cvYu3dvjmP89TKzr7/+2mjZsqURGBhohIaGGp07dzZ+/PFHl22uHO+vl+glJSUZkoyDBw9e9WdqGK6X0F3N1S6hGzx4sFGuXDkjMDDQaNmypbF+/fpcL3379NNPjdq1axvFihVzOc9WrVoZderUyfWYf97PmTNnjMqVKxuNGzc2MjMzXbYbNGiQ4ePjY6xfv/6a5wBYjc0w3JiRAwAAigw+kwcAwKRI8gAAmBRJHgAAkyLJAwBgUiR5AABMiiQPAIBJkeQBADApU97xLrBRf2+HgAJ0etNkb4cAIJ8E5HOW8mS+uLC18P0tMmWSBwAgT2zmbmib++wAALAwKnkAgHV58GuQCyOSPADAumjXAwCAoohKHgBgXbTrAQAwKdr1AACgKKKSBwBYF+16AABMinY9AAAoiqjkAQDWRbseAACTol0PAACKIip5AIB10a4HAMCkaNcDAICiiEoeAGBdtOsBADAp2vUAAKAoopIHAFiXySt5kjwAwLp8zP2ZvLnfwgAAYGFU8gAA66JdDwCASZn8Ejpzv4UBAMDCqOQBANZFux4AAJOiXQ8AAIoiKnkAgHXRrgcAwKRo1wMAgKKISh4AYF206wEAMCna9QAAoCiikgcAWBftegAATIp2PQAAKIqo5AEA1kW7HgAAkzJ5kjf32QEAYGFU8gAA6zL5xDuSPADAumjXAwCAoohKHgBgXbTrAQAwKdr1AACgKKKSBwBYF+16AADMyWbyJE+7HgAAk6KSBwBYltkreZI8AMC6zJ3jadcDAGBWVPIAAMsye7ueSh4AYFk2m81jiztGjRqV4/k1a9Z0rr948aL69eunyMhIBQcHq3v37jp69Kjb50eSBwDAC+rUqaMjR444l7Vr1zrXDRo0SJ9//rkWLlyoNWvW6PDhw4qNjXX7GLTrAQCW5cl2vcPhkMPhcBmz2+2y2+25bl+sWDGVLVs2x3h6erpmzZql+fPnq23btpKkpKQk1apVSxs2bFDz5s3zHFOhq+R//fVX/frrr94Oo9B6se/durB1ssuybfFLzvXRFUrqwwlPKGVVoo5++4bef/0xlY4I8WLEyA8L5s9Tp/Zt1bRRPT3c8wHt3LHD2yEhH/F65x9PtusTExMVFhbmsiQmJl712Pv27VP58uVVpUoVPfzww0pJSZEkbd68WZmZmWrXrp1z25o1a6pSpUpav369W+dXKJL8pUuXNGLECIWFhSkqKkpRUVEKCwvTSy+9pMzMTG+HV+j8sP+wotoNcy53PjZJklQ8wF9Lp/aTYRjq9OS7att7kvz9fPXx231NP7nESpb990u9OT5Rff/ZTwsWfqKYmJp6um8fnTx50tuhIR/wehcdw4YNU3p6ussybNiwXLdt1qyZZs+erWXLlmnatGk6ePCgbr/9dv3xxx9KTU2Vv7+/wsPDXZ5TpkwZpaamuhVToWjXDxgwQIsXL9b48ePVokULSdL69es1atQonTx5UtOmTfNyhIXLpaxsHT35R47xFg2rqHL5SDXv9br+OHdRkvT4y3N1ZM14tb6lhr7ZuKegQ0U+mDsnSbH391DXbt0lSS+NHK3k5NVasvhj9XniSS9HB0/j9c5nHqx/rtWa/6tOnTo5/12/fn01a9ZMlStX1kcffaTAwECPxVQokvz8+fO1YMGCHCddsWJF9erViyT/F9UqldLPX43TRUemNu44qJff/Uy/pp6W3b+YDMOQI+OSc9uLjkvKzjZ0a8OqJHkTyMzI0E8//qA+T/R1jvn4+Kh581u1Y/tWL0aG/MDrnf8KS5czPDxcNWrU0P79+9W+fXtlZGQoLS3NpZo/evRorp/hX0uhaNfb7XZFRUXlGI+Ojpa/v3/BB1SIbdp1SE++/L7u6zdFz7z6oaJuitTX/xmk4OJ2/W/nIZ27kKFxz3ZRYICfigf467WEbipWzFdlS4Z6O3R4wOm008rKylJkZKTLeGRkpE6cOOGlqJBfeL2t4+zZszpw4IDKlSunJk2ayM/PTytXrnSu37Nnj1JSUpzd7rwqFJV8//79NXbsWCUlJTlbHQ6HQ+PGjVP//v2v+dzcZjMa2Vmy+fjmW7ze9NV3Pzr/vWvfYW3aeUh7vhyj7nc11pwl6/Xw87P0zvAH9c9erZSdbeijZZu15ccUZRuGF6MGgMLJW5X8kCFD1LlzZ1WuXFmHDx/WyJEj5evrq169eiksLEx9+vRRQkKCIiIiFBoaqgEDBqhFixZuzayXCkmS37p1q1auXKkKFSqoQYMGkqTt27crIyNDd955p8u1gYsXL3Z5bmJiokaPHu0y5lumqfzK3ZL/gRcC6WcvaH/KMVWtWEqStHLDbtW5b7Qiw4N06VK20s9e0MEVr+rQ8s1ejhSeUCK8hHx9fXNMujp58qRKlizppaiQX3i985+3kvxvv/2mXr166eTJkypVqpRuu+02bdiwQaVKXf5bPmnSJPn4+Kh79+5yOBzq0KGDpk6d6vZxCkWSDw8PV/fu3V3GKlasmKfnDhs2TAkJCS5jpW8f6rHYCrugQH9FVyip1C/+5zJ+Mu2cJKlV0xoqHRGspWt2eiM8eJifv79q1a6jjRvWq+2dly+vyc7O1saN69Wz1z+8HB08jdfbvBYsWHDN9QEBAZoyZYqmTJlyQ8cpFEk+KSnpup+b22xGs7bqJSlxUDd9kbxTKYdPqXzpML301D3Kys7WR8suV+qP3Ndcew6m6vjps2pWP1pvPne/3p33jfb9cszLkcNTHonrrRHDh6pOnbqqW6++3p87RxcuXFDXbu7fDQuFH693/iosE+/yi1eTfIkSJXL9AYeFhalGjRoaMmSI2rdv74XICq+byoTrvcTeiggrrhOnz2rdtp/V6tEJOnH6rCSpRlRpjRlwnyLCiuuXw6c0ftZyvfP+Ki9HDU/q2OlunT51SlMnv6MTJ44rpmYtTZ3xb0XSvjUlXu98Zu4cL5theG9G1pw5c3IdT0tL0+bNm/Xhhx9q0aJF6ty5s1v7DWx07cl6MJfTmyZ7OwQA+SQgn0vRyLgPPLavk3N6eWxfnuLVSj4uLu6a6xs2bKjExES3kzwAAHlh9nZ9obhO/mruvfde7d6929thAABMyltfNVtQCnWSdzgc3AwHAIDrVChm11/NrFmz1LBhQ2+HAQAwqcJagXuKV5P8X69vvyI9PV1btmzR3r17lZycXMBRAQAsw9w53rtJfuvW3L9gITQ0VO3bt9fixYsVHR1dwFEBAGAOXk3y33zzjTcPDwCwONr1AACYlNmTfKGeXQ8AAK4flTwAwLLMXsmT5AEAlmX2JE+7HgAAk6KSBwBYl7kLeZI8AMC6aNcDAIAiiUoeAGBZZq/kSfIAAMsye5KnXQ8AgElRyQMArMvchTxJHgBgXbTrAQBAkUQlDwCwLLNX8iR5AIBlmT3J064HAMCkqOQBAJZl9kqeJA8AsC5z53ja9QAAmBWVPADAsmjXAwBgUmZP8rTrAQAwKSp5AIBlmbyQJ8kDAKyLdj0AACiSqOQBAJZl8kKeJA8AsC7a9QAAoEiikgcAWJbJC3mSPADAunx8zJ3ladcDAGBSVPIAAMsye7ueSh4AAJOikgcAWJbZL6EjyQMALMvkOZ52PQAAZkUlDwCwLNr1AACYlNmTPO16AABMikoeAGBZJi/kSfIAAOuiXQ8AAIokKnkAgGWZvJCnkgcAWJfNZvPYcr1ee+012Ww2DRw40Dl28eJF9evXT5GRkQoODlb37t119OhRt/dNkgcAwEs2bdqkGTNmqH79+i7jgwYN0ueff66FCxdqzZo1Onz4sGJjY93eP0keAGBZNpvnFnedPXtWDz/8sP71r3+pRIkSzvH09HTNmjVLEydOVNu2bdWkSRMlJSVp3bp12rBhg1vHIMkDACzLk+16h8OhM2fOuCwOh+Oqx+7Xr5/uuecetWvXzmV88+bNyszMdBmvWbOmKlWqpPXr17t1fiR5AAA8IDExUWFhYS5LYmJirtsuWLBAW7ZsyXV9amqq/P39FR4e7jJepkwZpaamuhUTs+sBAJblydn1w4YNU0JCgsuY3W7Psd2vv/6qZ599VitWrFBAQIDnAsgFSR4AYFmevBmO3W7PNan/1ebNm3Xs2DE1btzYOZaVlaXk5GRNnjxZy5cvV0ZGhtLS0lyq+aNHj6ps2bJuxUSSBwCgAN15553auXOny1jv3r1Vs2ZNDR06VBUrVpSfn59Wrlyp7t27S5L27NmjlJQUtWjRwq1jmTLJn9402dshoADN3HDQ2yGgAD3ZPNrbIcBEvHEznJCQENWtW9dlLCgoSJGRkc7xPn36KCEhQREREQoNDdWAAQPUokULNW/e3K1jmTLJAwCQF4X13vWTJk2Sj4+PunfvLofDoQ4dOmjq1Klu74ckDwCAl61evdrlcUBAgKZMmaIpU6bc0H5J8gAAyyqkhbzHkOQBAJZVWNv1nsLNcAAAMCkqeQCAZZm8kCfJAwCsi3Y9AAAokqjkAQCWZfZKniQPALAsk+d42vUAAJgVlTwAwLJo1wMAYFImz/G06wEAMCsqeQCAZdGuBwDApEye42nXAwBgVlTyAADL8jF5KU+SBwBYlslzPO16AADMikoeAGBZzK4HAMCkfMyd42nXAwBgVlTyAADLol0PAIBJmTzH064HAMCsqOQBAJZlk7lLeZI8AMCymF0PAACKJCp5AIBlMbseAACTMnmOp10PAIBZUckDACyLr5oFAMCkTJ7jadcDAGBWVPIAAMtidj0AACZl8hxPux4AALOikgcAWBaz6wEAMClzp3ja9QAAmBaVPADAsphdDwCASfFVswAAoEiikgcAWBbtekmfffZZnnd43333XXcwAAAUJJPn+Lwl+a5du+ZpZzabTVlZWTcSDwAA8JA8Jfns7Oz8jgMAgAJHux4AAJMy++z660ry586d05o1a5SSkqKMjAyXdc8884xHAgMAADfG7SS/detW3X333Tp//rzOnTuniIgInThxQsWLF1fp0qVJ8gCAIsPs7Xq3r5MfNGiQOnfurNOnTyswMFAbNmzQL7/8oiZNmujNN9/MjxgBAMgXNg8uhZHbSX7btm0aPHiwfHx85OvrK4fDoYoVK2r8+PEaPnx4fsQIAACug9tJ3s/PTz4+l59WunRppaSkSJLCwsL066+/ejY6AADykY/N5rGlMHI7yTdq1EibNm2SJLVq1Uovv/yy5s2bp4EDB6pu3brXFUSVKlV08uTJHONpaWmqUqXKde0TAIC/Y7N5bimM3E7yr776qsqVKydJGjdunEqUKKGnn35ax48f18yZM68riEOHDuV6Ex2Hw6Hff//9uvYJAIDVuT27/uabb3b+u3Tp0lq2bNl1H/zPt8tdvny5wsLCnI+zsrK0cuVKRUVFXff+AQC4Fm/Nrp82bZqmTZumQ4cOSZLq1Kmjl19+WZ06dZIkXbx4UYMHD9aCBQvkcDjUoUMHTZ06VWXKlHHrOF69Gc6fb5cbFxfnss7Pz09RUVGaMGFCAUcFALAKb7XZK1SooNdee03Vq1eXYRiaM2eOunTpoq1bt6pOnToaNGiQvvjiCy1cuFBhYWHq37+/YmNj9d1337l1HLeTfHR09DXf+fz888952s+OHTuUmZkpX19fRUdHa9OmTSpZsqS74eD/LJg/T3OSZunEieOqEVNTLwwfoXr163s7LNygzV8s0M9bvtPpI7+pmL+/ylatrRYPPKYSZSvm2NYwDC19a4RSdn2vTv1eVpXGt3ohYuQHfr/Np3Pnzi6Px40bp2nTpmnDhg2qUKGCZs2apfnz56tt27aSpKSkJNWqVUsbNmxQ8+bN83wct5P8wIEDXR5nZmZq69atWrZsmZ577rk876dRo0ZKTU1VqVKlZLPZTH9Dgvy07L9f6s3xiXpp5GjVq9dA8+bO0dN9++jTpcsUGRnp7fBwAw7v3am6bTqrdHQNGdnZ2vBxkj6b8KIeemWm/OwBLttuX/FJ4Z39g+vG73f+8uSseIfDIYfD4TJmt9tlt9uv+bysrCwtXLhQ586dU4sWLbR582ZlZmaqXbt2zm1q1qypSpUqaf369W4lebcn3j377LMuy5AhQzRv3jyNGTNGe/bsyfN+wsPDnVX/L7/8wpfg3IC5c5IUe38Pde3WXVWrVdNLI0crICBASxZ/7O3QcIM6DxqnWrfdpcibolSyYhXd2Wewzp46puOH9rlsdzzlgLZ9tVhtew/yUqTIL/x+5y9Pzq5PTExUWFiYy5KYmHjVY+/cuVPBwcGy2+166qmn9Mknn6h27dpKTU2Vv7+/wsPDXbYvU6aMUlNT3To/j30m36lTJw0bNkxJSUl52r579+5q1aqVc6b+zTffLF9f31y3zetHAFaUmZGhn378QX2e6Osc8/HxUfPmt2rH9q1ejAz5wXH+vCTJHhTiHMt0XNSKma/rjof7KSgswluhIR/w+120DBs2TAkJCS5j16riY2JitG3bNqWnp2vRokWKi4vTmjVrPBqTx5L8okWLFBGR9z8wM2fOVGxsrPbv369nnnlGTzzxhEJCQv7+iX+RW3vE8P379ohZnE47raysrBxtu8jISB08yJsjMzGys7V2wXSVq1ZbkRWinONrP5yhstVqqUqjFt4LDvmC3+/858mPivPSmv8zf39/VatWTZLUpEkTbdq0SW+//bYefPBBZWRkKC0tzaWaP3r0qMqWLetWTG4n+UaNGrn8UAzDUGpqqo4fP66pU6e6ta+OHTtKkjZv3qxnn332upJ8YmKiRo8e7TL24oiReunlUW7vCyjM1sybolO/H1LsC///ipOD29br95+2q8fIKV6MDCi63P7MOh9lZ2fL4XCoSZMm8vPz08qVK9W9e3dJ0p49e5SSkqIWLdx7M+92ku/SpYtLkvfx8VGpUqXUunVr1axZ093dSZKzxb9//34dOHBAd9xxhwIDA2UYxt++y8qtPWL4WqOKl6QS4SXk6+ub446BJ0+e5GoFE0meN0W/bN+obkPfVHBEKef4bz9tV/rxI/r3gO4u2y+b+orK1aijbs+/UdChwoP4/TavYcOGqVOnTqpUqZL++OMPzZ8/X6tXr3beM6ZPnz5KSEhQRESEQkNDNWDAALVo0cKtSXfSdST5UaNGufuUv3Xq1Ck98MAD+uabb2Sz2bRv3z5VqVJFffr0UYkSJa55rXxu7ZGLlzweYqHl5++vWrXraOOG9Wp75+WZmNnZ2dq4cb169vqHl6PDjTIMQ9/On6qft6xT1+fHK7SUa6uu8d09VPv2ji5jC0Y+pZY9n1R0A/f+GKDw4fc7/3nryq5jx47p0Ucf1ZEjRxQWFqb69etr+fLlat++vSRp0qRJ8vHxUffu3V1uhuMut5O8r6+vjhw5otKlS7uMnzx5UqVLl8719rR/Z+DAgfLz81NKSopq1arlHH/wwQeVkJDADXH+xiNxvTVi+FDVqVNXdevV1/tz5+jChQvq2i3W26HhBiW/P0V7N36juweMlF9AoM6ln5Ik2QODVMzfrqCwiFwn24VElM7xhgBFE7/f+cvHS1edzpo165rrAwICNGXKFE2ZcmMfxbmd5A3DyHXc4XDI39//uoL46quvtHz5clWoUMFlvHr16vrll1+ua59W0rHT3Tp96pSmTn5HJ04cV0zNWpo649+KpJ1X5O1avVSStGT88y7jbXsnqNZtd3kjJBQwfr9xI/Kc5N955x1Jl1sb//73vxUcHOxcl5WVpeTk5Ov+TP7cuXMqXrx4jvFTp05ZZpb8jer18D/U62Had2bTb5b73w1xPc9B4cbvd/7xViVfUPKc5CdNmiTpciU/ffp0l2va/f39FRUVpenTp19XELfffrvee+89jR07VtLlNxLZ2dkaP368WrdufV37BADg75j9bqt5TvIHDx6UJLVp00aLFy9WiRIlPBbE+PHjdeedd+r7779XRkaGnn/+ef3www86deqU2zfjBwAAl7l9ieA333zj0QQvSXXr1tXevXt12223qUuXLjp37pxiY2P1v//9T6+//rpHjwUAwBU+Ns8thZHbE++6d++uW265RUOHDnUZHz9+vDZt2qSFCxdeVyBhYWF68cUXXca2b9+uWbNmaebMmde1TwAArsXk3Xr3K/nk5GTdfffdOcY7deqk5ORkjwQFAABunNuV/NmzZ3O9VM7Pz09nzpzxSFAAABQET37VbGHkdiVfr149ffjhhznGFyxYoNq1a3skKAAACoKPB5fCyO1KfsSIEYqNjdWBAwfUtm1bSdLKlSs1f/58LVq0yK19xcZe+45NaWlp7oYHAAD+j9tJvnPnzlqyZIleffVVLVq0SIGBgWrQoIFWrVrl1lfNSpcn2/3d+kcffdTdEAEAyBOTd+uv7/vk77nnHt1zzz2SpDNnzuiDDz7QkCFDtHnzZrfuXX/l2+cAAPAGPpO/iuTkZMXFxal8+fKaMGGC2rZtqw0bNngyNgAAcAPcquRTU1M1e/ZszZo1S2fOnFGPHj3kcDi0ZMkSJt0BAIockxfyea/kO3furJiYGO3YsUNvvfWWDh8+rHfffTc/YwMAIF9xx7v/89///lfPPPOMnn76aVWvXj0/YwIAAB6Q50p+7dq1+uOPP9SkSRM1a9ZMkydP1okTJ/IzNgAA8pWPzeaxpTDKc5Jv3ry5/vWvf+nIkSPq27evFixYoPLlyys7O1srVqzQH3/8kZ9xAgDgcTab55bCyO3Z9UFBQXrssce0du1a7dy5U4MHD9Zrr72m0qVL67777suPGAEAwHW4oTvxxcTEaPz48frtt9/0wQcfeComAAAKBBPv8sDX11ddu3ZV165dPbE7AAAKhE2FNDt7SGG9pz4AALhBHqnkAQAoigprm91TSPIAAMsye5KnXQ8AgElRyQMALMtWWC9w9xCSPADAsmjXAwCAIolKHgBgWSbv1pPkAQDWVVi/WMZTaNcDAGBSVPIAAMsy+8Q7kjwAwLJM3q2nXQ8AgFlRyQMALMvH5N9CR5IHAFgW7XoAAFAkUckDACyL2fUAAJgUN8MBAABFEpU8AMCyTF7Ik+QBANZFux4AABRJVPIAAMsyeSFPkgcAWJfZ29lmPz8AACyLSh4AYFk2k/frSfIAAMsyd4qnXQ8AgGlRyQMALMvs18mT5AEAlmXuFE+7HgAA06KSBwBYlsm79SR5AIB1mf0SOtr1AAAUsMTERDVt2lQhISEqXbq0unbtqj179rhsc/HiRfXr10+RkZEKDg5W9+7ddfToUbeOQ5IHAFiWjwcXd6xZs0b9+vXThg0btGLFCmVmZuquu+7SuXPnnNsMGjRIn3/+uRYuXKg1a9bo8OHDio2Ndes4NsMwDDdjK/QuXvJ2BChIMzcc9HYIKEBPNo/2dggoQAH5/KHyR9sOe2xfPRqWv+7nHj9+XKVLl9aaNWt0xx13KD09XaVKldL8+fN1//33S5J2796tWrVqaf369WrevHme9kslDwCABzgcDp05c8ZlcTgceXpuenq6JCkiIkKStHnzZmVmZqpdu3bObWrWrKlKlSpp/fr1eY6JJA8AsCybB5fExESFhYW5LImJiX8bQ3Z2tgYOHKiWLVuqbt26kqTU1FT5+/srPDzcZdsyZcooNTU1z+fH7HoAgGV5cnb9sGHDlJCQ4DJmt9v/9nn9+vXTrl27tHbtWo/FcgVJHkUen9Fay7f7Tng7BBSg9rVKejuEPLPb7XlK6n/Wv39/LV26VMnJyapQoYJzvGzZssrIyFBaWppLNX/06FGVLVs2z/unXQ8AsCxvza43DEP9+/fXJ598olWrVik62rVYadKkifz8/LRy5Urn2J49e5SSkqIWLVrk+ThU8gAAy/LWzXD69eun+fPn69NPP1VISIjzc/awsDAFBgYqLCxMffr0UUJCgiIiIhQaGqoBAwaoRYsWeZ5ZL5HkAQAocNOmTZMktW7d2mU8KSlJ8fHxkqRJkybJx8dH3bt3l8PhUIcOHTR16lS3jsN18gCKFD6Tt5b8/kx+yY68z1T/O13r5/2z8oJCJQ8AsCyT37qeiXcAAJgVlTwAwLJ8ZO5SniQPALAs2vUAAKBIopIHAFiWjXY9AADmRLseAAAUSVTyAADLYnY9AAAmRbseAAAUSVTyAADLMnslT5IHAFiW2S+ho10PAIBJUckDACzLx9yFPEkeAGBdtOsBAECRRCUPALAsZtcDAGBStOsBAECRRCUPALAsZtcDAGBStOsBAECRRCUPALAsZtcDAGBSJs/xtOsBADArKnkAgGX5mLxfT5IHAFiWuVM87XoAAEyLSh4AYF0mL+VJ8gAAy+JmOAAAoEiikgcAWJbJJ9eT5AEA1mXyHE+7HgAAs6KSBwBYl8lLeZI8AMCymF0PAACKJCp5AIBlmX12PZU8AAAmRSUPALAskxfyJHkAgIWZPMvTrgcAwKSo5AEAlsUldAUgOTlZly5dyjF+6dIlJScneyEiAIAV2GyeWwqjQpHk27Rpo1OnTuUYT09PV5s2bbwQEQAARV+haNcbhiFbLm+DTp48qaCgIC9EBACwgkJagHuMV5N8bGysJMlmsyk+Pl52u925LisrSzt27NCtt97qrfAAAGZn8izv1SQfFhYm6XIlHxISosDAQOc6f39/NW/eXE888YS3wgMAoEjzapJPSkqSJEVFRWnIkCG05gEABcrss+sLxWfyI0eO9HYIAAALKqyz4j2lUMyuP3r0qB555BGVL19exYoVk6+vr8sCAADcVygq+fj4eKWkpGjEiBEqV65crjPtAQDwNLNnm0KR5NeuXatvv/1WDRs29HYoAAArMXmWLxRJvmLFijIMw9thFGkL5s/TnKRZOnHiuGrE1NQLw0eoXv363g4L+YTX25z2/7BNX38yXykHduvM6ZN64oVENWh+h3N9/64tc31e17h/ql23hwsqTBQhheIz+bfeeksvvPCCDh065O1QiqRl//1Sb45PVN9/9tOChZ8oJqamnu7bRydPnvR2aMgHvN7m5bh4QTdFV9ODfQfnuv7VpM9clocHDJfNZlPDFq0LNlATsXnwP3ckJyerc+fOKl++vGw2m5YsWeKy3jAMvfzyyypXrpwCAwPVrl077du3z+3z81qSL1GihCIiIhQREaGePXtq9erVqlq1qkJCQpzjVxZc29w5SYq9v4e6duuuqtWq6aWRoxUQEKAliz/2dmjIB7ze5lWnSQt1fvhJNWjeKtf1oSUiXZadG79V9bqNVbLsTQUcqXl46971586dU4MGDTRlypRc148fP17vvPOOpk+fro0bNyooKEgdOnTQxYsX3TqO19r1b731lrcObSqZGRn66ccf1OeJvs4xHx8fNW9+q3Zs3+rFyJAfeL1xxZm0U9q1eZ0eeeYlb4eC/+NwOORwOFzG7Ha7y91cr+jUqZM6deqU634Mw9Bbb72ll156SV26dJEkvffeeypTpoyWLFminj175jkmryX5uLg4bx3aVE6nnVZWVpYiIyNdxiMjI3Xw4M9eigr5hdcbV2xc9V8FBBZXwxa5V/3IG0/Ou0tMTNTo0aNdxkaOHKlRo0a5tZ+DBw8qNTVV7dq1c46FhYWpWbNmWr9+fdFI8n925syZXMdtNpvsdrv8/f2v+tzc3jkZvrm/cwIAs9iwcqluvuMu+fnzt+6GeDDLDxs2TAkJCS5j15OLUlNTJUllypRxGS9TpoxzXV4Viol34eHhKlGiRI4lPDxcgYGBqly5skaOHKns7Owcz01MTFRYWJjL8sbriV44C+8oEV5Cvr6+OSZdnTx5UiVLlvRSVMgvvN6QLs/CP/p7im5t39nboeBP7Ha7QkNDXRZvF5yFIsnPnj1b5cuX1/Dhw7VkyRItWbJEw4cP10033aRp06bpySef1DvvvKPXXnstx3OHDRum9PR0l+W5ocO8cBbe4efvr1q162jjhvXOsezsbG3cuF71GzTyYmTID7zekKT1Xy9VxaoxqhBd3duhFHneml1/LWXLlpV0+W6wf3b06FHnurwqFO36OXPmaMKECerRo4dzrHPnzqpXr55mzJihlStXqlKlSho3bpyGDx/u8tzcJjVcvFQgYRcaj8T11ojhQ1WnTl3VrVdf78+dowsXLqhrt1hvh4Z8wOttXo4L53X8yG/OxyePHdZvP+9V8ZBQRZS6/Mf9wvlz2rruG3Xr3d9bYZpKYbzBanR0tMqWLauVK1c6bxJ35swZbdy4UU8//bRb+yoUSX7dunWaPn16jvFGjRpp/frLFcttt92mlJSUgg6tSOjY6W6dPnVKUye/oxMnjiumZi1NnfFvRdK+NSVeb/P6Zf9uvTNigPPx4v+8K0lq1qaTHnn28iz6zd9+LcMwdPPt7b0SIzzj7Nmz2r9/v/PxwYMHtW3bNkVERKhSpUoaOHCgXnnlFVWvXl3R0dEaMWKEypcvr65du7p1HJtRCG41V6NGDcXGxuZox7/wwgv65JNPtGfPHn3//ffq0qWLfv/997/dn9UqecBKvt13wtshoAC1r5W/b173pp732L5qlC2e521Xr16tNm3a5BiPi4vT7NmzZRiGRo4cqZkzZyotLU233Xabpk6dqho1argVU6FI8p999pkeeOAB1axZU02bNpUkff/999q9e7cWLVqke++9V9OmTdO+ffs0ceLEv90fSR4wL5K8teR7kj/qwSRfJu9JvqAUiiQvXW5VzJw5U3v27JEkxcTEqG/fvoqKinJ7XyR5wLxI8tZCkr8xhSbJexJJHjAvkry15HeS33f0gsf2Vb1MoMf25Slem3i3Y8cO1a1bVz4+PtqxY8c1t63Pt2sBAPJBYZxd70leS/INGzZUamqqSpcurYYNG8pms+X6dbM2m01ZWVleiBAAgKLNa0n+4MGDKlWqlPPfV3Pu3LmCCgkAYDEmL+S9l+QrV66c67+vcDgcmjJlisaPH+/2vXoBAMgTk2d5r97W1uFwaNiwYbr55pt16623asmSJZKkpKQkRUdHa9KkSRo0aJA3QwQAoMjy6h3vXn75Zc2YMUPt2rXTunXr9MADD6h3797asGGDJk6cqAceeEC+vr7eDBEAYGKevOd8YeTVJL9w4UK99957uu+++7Rr1y7Vr19fly5d0vbt22Uz+5RHAIDXmT3VeLVd/9tvv6lJkyaSpLp168put2vQoEEkeAAAPMCrlXxWVpb8/f2dj4sVK6bg4GAvRgQAsBKzl5ReTfKGYSg+Pt75VbEXL17UU089paCgIJftFi9e7I3wAABmZ/Is79UkHxcX5/L4H//4h5ciAQDAfLya5JOSkrx5eACAxTG7HgAAkzL7PG+vzq4HAAD5h0oeAGBZJi/kSfIAAOuiXQ8AAIokKnkAgIWZu5QnyQMALIt2PQAAKJKo5AEAlmXyQp4kDwCwLtr1AACgSKKSBwBYFveuBwDArMyd42nXAwBgVlTyAADLMnkhT5IHAFgXs+sBAECRRCUPALAsZtcDAGBW5s7xtOsBADArKnkAgGWZvJAnyQMArIvZ9QAAoEiikgcAWBaz6wEAMCna9QAAoEgiyQMAYFK06wEAlkW7HgAAFElU8gAAy2J2PQAAJkW7HgAAFElU8gAAyzJ5IU+SBwBYmMmzPO16AABMikoeAGBZzK4HAMCkmF0PAACKJCp5AIBlmbyQJ8kDACzM5Fmedj0AAF4wZcoURUVFKSAgQM2aNdP//vc/jx+DJA8AsCybB/9zx4cffqiEhASNHDlSW7ZsUYMGDdShQwcdO3bMs+dnGIbh0T0WAhcveTsCAPnl230nvB0CClD7WiXzdf+ezBcBbnwA3qxZMzVt2lSTJ0+WJGVnZ6tixYoaMGCAXnjhBY/FRCUPAIAHOBwOnTlzxmVxOBw5tsvIyNDmzZvVrl0755iPj4/atWun9evXezQmU068c+fdlFk4HA4lJiZq2LBhstvt3g4H+czKr3d+V3aFkZVf7/zmyXwx6pVEjR492mVs5MiRGjVqlMvYiRMnlJWVpTJlyriMlylTRrt37/ZcQDJpu96Kzpw5o7CwMKWnpys0NNTb4SCf8XpbC6930eBwOHJU7na7Pccbs8OHD+umm27SunXr1KJFC+f4888/rzVr1mjjxo0ei8mCNS8AAJ6XW0LPTcmSJeXr66ujR4+6jB89elRly5b1aEx8Jg8AQAHy9/dXkyZNtHLlSudYdna2Vq5c6VLZewKVPAAABSwhIUFxcXG6+eabdcstt+itt97SuXPn1Lt3b48ehyRvEna7XSNHjmRSjkXwelsLr7f5PPjggzp+/LhefvllpaamqmHDhlq2bFmOyXg3iol3AACYFJ/JAwBgUiR5AABMiiQPAIBJkeQBkzAMQ08++aQiIiJks9m0bds2b4eEPDp06JDbr9ns2bMVHh6ebzHBHEjyRUjr1q01cODAHOP8sptHfHy8unbtel3PXbZsmWbPnq2lS5fqyJEjqlu3rmw2m5YsWeLRGOG++Ph42Ww22Ww2+fn5KTo6Ws8//7wuXrwoSapYsaLzNfP0ca/3/yeYA5fQASZx4MABlStXTrfeequ3Q0EuOnbsqKSkJGVmZmrz5s2Ki4uTzWbT66+/Ll9fX4/f6QyQqORN58o799GjR6tUqVIKDQ3VU089pYyMDG+Hhhu0a9cuderUScHBwSpTpoweeeQRnThx+WtX4+PjNWDAAKWkpMhmsykqKkpRUVGSpG7dujnH4D12u11ly5ZVxYoV1bVrV7Vr104rVqyQlHu7/rPPPlP16tUVEBCgNm3aaM6cObLZbEpLS3PZ7/Lly1WrVi0FBwerY8eOOnLkiCRp1KhRmjNnjj799FNnF2H16tUFdLYoLEjyJrRy5Ur99NNPWr16tT744AMtXrw4xzcjoWhJS0tT27Zt1ahRI33//fdatmyZjh49qh49ekiS3n77bY0ZM0YVKlTQkSNHtGnTJm3atEmSlJSU5BxD4bBr1y6tW7dO/v7+ua4/ePCg7r//fnXt2lXbt29X37599eKLL+bY7vz583rzzTc1d+5cJScnKyUlRUOGDJEkDRkyRD169HAm/iNHjtDlsSDa9Sbk7++v//znPypevLjq1KmjMWPG6LnnntPYsWPl48P7uqJo8uTJatSokV599VXn2H/+8x9VrFhRe/fuVY0aNRQSEpJr2zc8PJxWcCGwdOlSBQcH69KlS3I4HPLx8dHkyZNz3XbGjBmKiYnRG2+8IUmKiYnRrl27NG7cOJftMjMzNX36dFWtWlWS1L9/f40ZM0aSFBwcrMDAQDkcDl5/CyPJm1CDBg1UvHhx5+MWLVro7Nmz+vXXX1W5cmUvRobrtX37dn3zzTcKDg7Ose7AgQOqUaOGF6KCO9q0aaNp06bp3LlzmjRpkooVK6bu3bvnuu2ePXvUtGlTl7Fbbrklx3bFixd3JnhJKleunI4dO+bZwFGkkeSLkNDQUKWnp+cYT0tLU1hYmBciQkE5e/asOnfurNdffz3HunLlynkhIrgrKChI1apVk3S5C9OgQQPNmjVLffr0ue59+vn5uTy22WziTuX4M3q3RUhMTIy2bNmSY3zLli0uldz27dt14cIF5+MNGzYoODhYFStWLJA44XmNGzfWDz/8oKioKFWrVs1lCQoKuurz/Pz8lJWVVYCRIi98fHw0fPhwvfTSSy6/q1fExMTo+++/dxm7njkV/v7+vP4WR5IvQp5++mnt3btXzzzzjHbs2KE9e/Zo4sSJ+uCDDzR48GDndhkZGerTp49+/PFHffnllxo5cqT69+/P5/FFRHp6urZt2+ayPPnkkzp16pR69eqlTZs26cCBA1q+fLl69+59zT/iUVFRWrlypVJTU3X69OkCPAv8nQceeEC+vr6aMmVKjnV9+/bV7t27NXToUO3du1cfffSRZs+eLelytZ5XUVFRzr8VJ06cUGZmpqfCRxHBX/0ipEqVKkpOTtbu3bvVrl07NWvWTB999JEWLlyojh07Ore78847Vb16dd1xxx168MEHdd9992nUqFHeCxxuWb16tRo1auSyjB07Vt99952ysrJ01113qV69eho4cKDCw8Ov+eZtwoQJWrFihSpWrKhGjRoV4Fng7xQrVkz9+/fX+PHjde7cOZd10dHRWrRokRYvXqz69etr2rRpztn17nzd7BNPPKGYmBjdfPPNKlWqlL777juPngMKP75q1mTi4+OVlpbGXc4Akxk3bpymT5+uX3/91duhoAhh4h0AFEJTp05V06ZNFRkZqe+++05vvPGG+vfv7+2wUMSQ5AGgENq3b59eeeUVnTp1SpUqVdLgwYM1bNgwb4eFIoZ2PQAAJsXEOwAATIokDwCASZHkAQAwKZI8AAAmRZIHAMCkSPJAERAfH6+uXbs6H7du3VoDBw4s8DhWr14tm82mtLS0Aj82APeR5IEbEB8fL5vNJpvNJn9/f1WrVk1jxozRpUuX8vW4ixcv1tixY/O0LYkZsC5uhgPcoI4dOyopKUkOh0Nffvml+vXrJz8/vxw3LsnIyJC/v79HjhkREeGR/QAwNyp54AbZ7XaVLVtWlStX1tNPP6127drps88+c7bYx40bp/LlyysmJkaS9Ouvv6pHjx4KDw9XRESEunTpokOHDjn3l5WVpYSEBIWHhysyMlLPP/98ju8I/2u73uFwaOjQoapYsaLsdruqVaumWbNm6dChQ2rTpo0kqUSJErLZbIqPj5ckZWdnKzExUdHR0QoMDFSDBg20aNEil+N8+eWXqlGjhgIDA9WmTRuXOAEUfiR5wMMCAwOVkZEhSVq5cqX27NmjFStWaOnSpcrMzFSHDh0UEhKib7/9Vt99952Cg4PVsWNH53MmTJig2bNn6z//+Y/Wrl2rU6dO6ZNPPrnmMR999FF98MEHeuedd/TTTz9pxowZCg4OVsWKFfXxxx9Lkvbs2aMjR47o7bffliQlJibqvffe0/Tp0/XDDz9o0KBB+sc//qE1a9ZIuvxmJDY2Vp07d9a2bdv0+OOP64UXXsivHxuA/GAAuG5xcXFGly5dDMMwjOzsbGPFihWG3W43hgwZYsTFxRllypQxHA6Hc/u5c+caMTExRnZ2tnPM4XAYgYGBxvLlyw3DMIxy5coZ48ePd67PzMw0KlSo4DyOYRhGq1atjGeffdYwDMPYs2ePIclYsWJFrjF+8803hiTj9OnTzrGLFy8axYsXN9atW+eybZ8+fYxevXoZhmEYw4YNM2rXru2yfujQoTn2BaDw4jN54AYtXbpUwcHByszMVHZ2th566CGNGjVK/fr1U7169Vw+h9++fbv279+vkJAQl31cvHhRBw4cUHp6uo4cOaJmzZo51xUrVkw333xzjpb9Fdu2bZOvr69atWqV55j379+v8+fPq3379i7jGRkZzu+d/+mnn1zikKQWLVrk+RgAvI8kD9ygNm3aaNq0afL391f58uVVrNj//7UKCgpy2fbs2bNq0qSJ5s2bl2M/pUqVuq7jBwYGuv2cs2fPSpK++OIL3XTTTS7r7Hb7dcUBoPAhyQM3KCgoSNWqVcvTto0bN9aHH36o0qVLKzQ0NNdtypUrp40bN+qOO+6QJF26dEmbN29W48aNc92+Xr16ys7O1po1a9SuXbsc6690ErKyspxjtWvXlt1uV0pKylU7ALVq1dJnn33mMrZhw4a/P0kAhQYT74AC9PDDD6tkyZLq0qWLvv32Wx08eFCrV6/WM888o99++02S9Oyzz+q1117TkiVLtHv3bv3zn/+85jXuUVFRiouL02OPPaYlS5Y49/nRRx9JkipXriybzaalS5fq+PHjOnv2rEJCQjRkyBANGjRIc+bM0YEDB7Rlyxa9++67mjNnjiTpqaee0r59+/Tcc89pz549mj9/vmbPnp3fPyIAHkSSBwpQ8eLFlZycrEqVKik2Nla1atVSnz59dPHiRWdlP3jwYD3yyCOKi4tTixYtFBISom7dul1zv9OmTdP999+vf/7zn6pZs6aeeOIJnTt3TpJ00003afTo0XrhhRdUpkwZ9e/fX5I0duxYjRgxQomJiapVq5Y6duyoL774QtHR0ZKkSpUq6eOPP9aSJUvUoEEDTZ8+Xa+++mo+/nQAeJrNuNpsHgAAUKRRyQMAYFIkeQAATIokDwCASZHkAQAwKZI8AAAmRZIHAMCkSPIAAJgUSR4AAJMiyQMAYFIkeQAATIokDwCASf0/7zcvcPWNUV4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Part 3: Behavioral Cloning with Visual Observations\n",
            "\n",
            "Training SVM and Gradient Boosting classifiers using extracted histograms...\n",
            "\n",
            "Data Structures:\n",
            "Images shape: (400, 64, 64, 3)\n",
            "Actions shape: (400, 1)\n",
            "\n",
            "Data Structures after reshaping:\n",
            "Actions reshaped shape: (400,)\n",
            "\n",
            "Class Distribution: Counter({0: 213, 1: 170, 2: 17})\n",
            "\n",
            "Extracting keypoints/patches from images and clusters them into a visual vocabulary using Kmeans.\n",
            "The observations data set is a batch of observations (images or vectors).\n",
            "\n",
            "Evaluating on testing data...\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.11.0) /io/opencv/modules/features2d/src/sift.dispatch.cpp:512: error: (-5:Bad argument) image is empty or has incorrect depth (!=CV_8U) in function 'detectAndCompute'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-118-b78fe354d031>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Our code that evaluates your implementations on all three parts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscore_policy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mscore_all_parts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPOSBCRobot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRGBBCRobot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPositionRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgui_enable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/score_policy.py\u001b[0m in \u001b[0;36mscore_all_parts\u001b[0;34m(pos_bc_robot, rgb_bc_robot, pos_regressor, gui_enable)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscore_all_parts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_bc_robot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrgb_bc_robot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_regressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgui_enable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mscore_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_position_bc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_bc_robot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgui_enable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgui_enable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0mscore_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_img_bc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrgb_bc_robot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgui_enable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgui_enable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0mscore_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_regressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregressor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_regressor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mfinal_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscore_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_reg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/score_policy.py\u001b[0m in \u001b[0;36mscore_img_bc\u001b[0;34m(policy, gui_enable)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscore_img_bc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgui_enable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/bc_data.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mgui_enable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgui_enable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_obs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgui_enable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-117-1a9aceefcaf4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m#self.evaluate(data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluating on testing data...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-117-1a9aceefcaf4>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, test_data)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;31m# Predict actions using the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mpredicted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# Compute accuracy and classification report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-117-1a9aceefcaf4>\u001b[0m in \u001b[0;36mget_actions\u001b[0;34m(self, observations)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;31m#print(\"\\nPredicting actions using trained classifiers SVM and GB.\")  # prints too much\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mfeature_histograms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_to_feature_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobservations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0mfeature_histograms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_histograms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-117-1a9aceefcaf4>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;31m#print(\"\\nPredicting actions using trained classifiers SVM and GB.\")  # prints too much\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mfeature_histograms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_to_feature_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobservations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0mfeature_histograms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_histograms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-117-1a9aceefcaf4>\u001b[0m in \u001b[0;36mimage_to_feature_histogram\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0msift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIFT_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mkeypoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescriptors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdescriptors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) /io/opencv/modules/features2d/src/sift.dispatch.cpp:512: error: (-5:Bad argument) image is empty or has incorrect depth (!=CV_8U) in function 'detectAndCompute'\n"
          ]
        }
      ],
      "source": [
        "# do NOT change\n",
        "\n",
        "# Our code that evaluates your implementations on all three parts\n",
        "from score_policy import *\n",
        "score_all_parts(POSBCRobot(), RGBBCRobot(), PositionRegressor(), gui_enable=gui)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8I3gqaxOnig0"
      },
      "source": [
        "### Show GUI (optional, you may change)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vz3iUfjdVsxp"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "Image(filename='pos_bc_anim.png', width=200, height=200)\n",
        "Image(filename='rgb_bc_anim.png', width=200, height=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHDj84RNpCvk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}