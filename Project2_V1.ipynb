{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "D1vjDH2fL9Tu"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nprimavera/Robot-Learning/blob/main/mecs6616_Spring2025_Project2_ncp2136.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MECS6616 Spring 2025 - Project 2**"
      ],
      "metadata": {
        "id": "6pC8PaXzq2js"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction**\n",
        "\n",
        "***IMPORTANT:***\n",
        "- **Before starting, make sure to read the [Assignment Instructions](https://courseworks2.columbia.edu/courses/197115/pages/assignment-instructions) page on Courseworks to understand the workflow and submission requirements for this project.**\n",
        "\n",
        "This project aims to demonstrate how neural networks can be used in a robotics setting. We will continue using the 2D maze environment introduced in Project 1 and learn to navigate an agent to a goal. Since neural networks can be more powerful models than the ones we had access to in Project 1, we can afford to make some changes to the 2D maze environment and make the problem more difficult. The project is divided into three parts: In Part I, you will train a simple Deep Neural Network (DNN) to predict the optimal action towards the goal given the agent position and the goal position. In Parts II and III, you will train Convolutional Neural Networks (CNNs) to predict the optimal action given images of the maze environment.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/roamlab/robot-learning-S2023/blob/main/project2/imgs/P1_side.png?raw=true\" width=\"300\"/>\n",
        "</div>\n",
        "\n",
        "The figure above illustrates the simulation world, where the \"robot\" (also referred to as \"agent\") is represented by a green dot, and the goal location is marked by a red square. The agent's objective is to navigate to this goal location, avoiding any obstacles (depicted as black boxes) along the way.\n",
        "\n",
        "**Unlike the previous project, the robot and the goal are spawned at random positions in the maze.** Also, the action space now contains all four directions: 'up', 'down', 'left' and 'right'. Another change is that, in addition to the obstacle map shown above, we introduce two new obstacle maps as shown below. However, these new maps will not be used until Part III.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/roamlab/robot-learning-S2023/blob/main/project2/imgs/map1.png?raw=true\" width=\"300\"/>\n",
        "<img src=\"https://github.com/roamlab/robot-learning-S2023/blob/main/project2/imgs/map2.png?raw=true\" width=\"300\"/>\n",
        "<img src=\"https://github.com/roamlab/robot-learning-S2023/blob/main/project2/imgs/map3.png?raw=true\" width=\"300\"/>\n",
        "</div>\n",
        "\n",
        "We want to learn to navigate the agent by imitating demonstrations from an expert user. In all three parts, you will be using data collected by a human controlling the agent via a keyboard for training."
      ],
      "metadata": {
        "id": "inY7y5CRo97q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Setup (do NOT change)**\n",
        "\n",
        "***IMPORTANT:***\n",
        "- Do NOT change this \"*Project Setup*\" section\n",
        "- Do NOT install any other dependencies or a different version of an already provided package. You may, however, import other packages\n",
        "- Your code should go under the subsequent sections with headings \"*Part 1*\", \"*Part 2*\", and \"*Part 3*\"\n",
        "- You may find it useful to minimize sections using the arrows located to the left of each section heading\n",
        "- You may not use pre-trained models or any form of transfer learning for Part 2 and Part 3\n",
        "\n",
        "You will be accessing data files located in a Google Drive folder. The following cell downloads the data from the cloud"
      ],
      "metadata": {
        "id": "D1vjDH2fL9Tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE\n",
        "# Download data\n",
        "!wget https://www.dropbox.com/scl/fi/gy1d0ifkwuusmdjv796dl/project2.zip?rlkey=h6wresrsqxiryhlvrssjla5hn&st=cfvqccqm&dl=0\n",
        "!mv project2.zip?rlkey=h6wresrsqxiryhlvrssjla5hn project2.zip"
      ],
      "metadata": {
        "id": "DptpWqf9awi7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "554463d1-3a9a-49e8-81d2-1deaca270099"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-23 23:36:34--  https://www.dropbox.com/scl/fi/gy1d0ifkwuusmdjv796dl/project2.zip?rlkey=h6wresrsqxiryhlvrssjla5hn\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.4.18, 2620:100:6018:18::a27d:312\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.4.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc0a44777585217705e44e967226.dl.dropboxusercontent.com/cd/0/inline/CkvMlBpZXgd2r49XCkTT7ybZRU13DMgq_NvgAcqerUrKs1c9CHsmRFXHkst0Nh1dZFB9UXUbB8QIC78U66MUPCW6nxJBiZLtE0t1xQPkq0m7Hv2-Q-cZRaN0hEg710sqqImQeJHq8DjyTHw9X2NenJBY/file# [following]\n",
            "--2025-02-23 23:36:35--  https://uc0a44777585217705e44e967226.dl.dropboxusercontent.com/cd/0/inline/CkvMlBpZXgd2r49XCkTT7ybZRU13DMgq_NvgAcqerUrKs1c9CHsmRFXHkst0Nh1dZFB9UXUbB8QIC78U66MUPCW6nxJBiZLtE0t1xQPkq0m7Hv2-Q-cZRaN0hEg710sqqImQeJHq8DjyTHw9X2NenJBY/file\n",
            "Resolving uc0a44777585217705e44e967226.dl.dropboxusercontent.com (uc0a44777585217705e44e967226.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:6018:15::a27d:30f\n",
            "Connecting to uc0a44777585217705e44e967226.dl.dropboxusercontent.com (uc0a44777585217705e44e967226.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/Cks4yBYYsPwJFAerSEEiUdH2Iygk8FQC9SFb-KxWzr328TvPxIZk5FxOD-zl-XucWNxJKe37J8inObT-ivnesCmGz166JsnEockhUigXKf6bQQGhXTnH80w-WG8dUk5nflRMVChBjk6UoHHrLUzlZ8g5hIC5hZ7s9orgejO0VGlsUYURRIXkMyk-qgMFxjEFz9a0wyUnT2PaEktSE-YVKlJePDK9u4F4b-mGhb92sNDrqEDXGJXMs-2TZwCd5E-gdw3iTGPEoVOzYLADqMFmYLlNn6MgV5hjL9eQlZdENsyHAs29dmCDJ_RXJdTO4f0HboY1CvgFeFP6K83PUwktFoo3vFDzo-NTDuKVarDz22K4TzER9F3_qACzqDGjG6ATzxQ/file [following]\n",
            "--2025-02-23 23:36:35--  https://uc0a44777585217705e44e967226.dl.dropboxusercontent.com/cd/0/inline2/Cks4yBYYsPwJFAerSEEiUdH2Iygk8FQC9SFb-KxWzr328TvPxIZk5FxOD-zl-XucWNxJKe37J8inObT-ivnesCmGz166JsnEockhUigXKf6bQQGhXTnH80w-WG8dUk5nflRMVChBjk6UoHHrLUzlZ8g5hIC5hZ7s9orgejO0VGlsUYURRIXkMyk-qgMFxjEFz9a0wyUnT2PaEktSE-YVKlJePDK9u4F4b-mGhb92sNDrqEDXGJXMs-2TZwCd5E-gdw3iTGPEoVOzYLADqMFmYLlNn6MgV5hjL9eQlZdENsyHAs29dmCDJ_RXJdTO4f0HboY1CvgFeFP6K83PUwktFoo3vFDzo-NTDuKVarDz22K4TzER9F3_qACzqDGjG6ATzxQ/file\n",
            "Reusing existing connection to uc0a44777585217705e44e967226.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13335134 (13M) [application/zip]\n",
            "Saving to: ‘project2.zip?rlkey=h6wresrsqxiryhlvrssjla5hn’\n",
            "\n",
            "project2.zip?rlkey= 100%[===================>]  12.72M  65.2MB/s    in 0.2s    \n",
            "\n",
            "2025-02-23 23:36:36 (65.2 MB/s) - ‘project2.zip?rlkey=h6wresrsqxiryhlvrssjla5hn’ saved [13335134/13335134]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure you have successfully uploaded the zip file to Colab before running the line below.\n",
        "# If wget fails to pull the zip file, you can download the zipfile from dropbox and manually upload it to collab instead\n",
        "# If you do decide to manually upload the file, use the dropbox link in the previous cell (after wget) to access the file\n",
        "# Make sure the zip file is named \"project2.zip\", rename it before uploading (if necessary)\n",
        "# Upload the entire zip file to google colab. Do not unzip before uploading\n",
        "\n",
        "# Unzip the uploaded zip file\n",
        "!unzip -o project2.zip -d /content/"
      ],
      "metadata": {
        "id": "8IYctlC5-gfU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "950ec224-5560-43ea-a404-b442891a48d7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  project2.zip\n",
            "   creating: /content/mjcf/\n",
            "  inflating: /content/mjcf/point_mass.xml  \n",
            "   creating: /content/mjcf/common/\n",
            "  inflating: /content/mjcf/common/skybox.xml  \n",
            "  inflating: /content/mjcf/common/visual.xml  \n",
            "  inflating: /content/mjcf/common/materials.xml  \n",
            "  inflating: /content/mjcf/test_mjcf.xml  \n",
            "  inflating: /content/dnn.py         \n",
            "   creating: /content/imgs/\n",
            "  inflating: /content/imgs/P1_side.png  \n",
            "  inflating: /content/imgs/map1.png  \n",
            "  inflating: /content/imgs/map3.png  \n",
            "  inflating: /content/imgs/map2.png  \n",
            "  inflating: /content/score_policy.py  \n",
            "  inflating: /content/simple_maze.py  \n",
            "  inflating: /content/data_utils.py  \n",
            "   creating: /content/data/\n",
            "  inflating: /content/data/map1.pkl  \n",
            "  inflating: /content/data/all_maps.pkl  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE\n",
        "\n",
        "# Install required packages\n",
        "!pip install pybullet numpngw"
      ],
      "metadata": {
        "id": "Y2w_kfLOMFIG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "449aa1b0-bb20-45b1-b2b1-528550ebeaa1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pybullet\n",
            "  Downloading pybullet-3.2.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting numpngw\n",
            "  Downloading numpngw-0.1.4-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from numpngw) (1.26.4)\n",
            "Downloading pybullet-3.2.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (103.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpngw-0.1.4-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: pybullet, numpngw\n",
            "Successfully installed numpngw-0.1.4 pybullet-3.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part I. Behavioral cloning with low dimensional data\n",
        "\n",
        "This part is a natural extension of Part II in Project 1, where your agent needs to learn a policy using labeled examples from an expert.\n",
        "\n",
        "Each labeled example $i$ will contain a tuple of the form $(o, a)^i$, where $o$ represents an observation and $a$ represents the action taken by the expert given that observation. You must simply learn to imitate the expert, a process also known as behavioral cloning. Note that while the observation space will be different in each part, the action space is the same for the rest of the project.\n",
        "\n",
        "We will be training a DNN policy to predict an action to be taken ('up', 'down', 'left', and 'right') based on the observation. **In Part I, the observation will contain the agent position and the current goal position.** (Since the goal is sampled randomly, the policy has to know the current goal to be reached). The environment thus returns an observation array of size (4, ) where the agent position is contained in the first two axes and the current goal position is contained in the next two. **In Part I, the map that the robot is navigating is always the same.**\n",
        "\n",
        "PyTorch and Tensorflow are two popular frameworks for building and training neural networks but for this class, we will be exclusively using PyTorch and you are allowed to use any of its features. A good starting point can be found [here](https://github.com/roamlab/robot-learning-S2024/blob/main/dnn_example.py).\n",
        "\n",
        "You will implement a class that inherits from `RobotPolicy` by providing implementations for the abstract methods from the class. These abstract methods will be re-used by future parts of the project, so do not edit them.\n",
        "\n"
      ],
      "metadata": {
        "id": "Wz0ALBOu6coY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE\n",
        "# base class\n",
        "\n",
        "import abc\n",
        "\n",
        "\n",
        "class RobotPolicy(abc.ABC):\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def train(self, data):\n",
        "        \"\"\"\n",
        "            Abstract method for training a policy.\n",
        "\n",
        "            Args:\n",
        "                data: a dict that contains X (key = 'obs') and y (key = 'actions').\n",
        "\n",
        "                X is either rgb image (N, 64, 64, 3) OR  agent & goal pos (N, 4)\n",
        "\n",
        "            Returns:\n",
        "                This method does not return anything. It will just need to update the\n",
        "                property of a RobotPolicy instance.\n",
        "        \"\"\"\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def get_action(self, obs):\n",
        "        \"\"\"\n",
        "            Abstract method for getting action. You can do data preprocessing and feed\n",
        "            forward of your trained model here.\n",
        "            Args:\n",
        "                obs: an observation (64 x 64 x 3) rgb image OR (4, ) positions\n",
        "\n",
        "            Returns:\n",
        "                action: an integer between 0 to 3\n",
        "        \"\"\""
      ],
      "metadata": {
        "id": "NAb3tE7h9uUd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement your solution for Part 1 below\n",
        "\n",
        "import torch    # PyTorch main library\n",
        "import torch.nn as nn   # Neural network modules (layers, loss functions, etc.)\n",
        "import torch.nn.functional as F   # Functional interface for neural networks\n",
        "\n",
        "from torch.utils.data.dataset import Dataset  # For creating custom datasets\n",
        "from torch.utils.data import DataLoader   # For loading data in batches\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D   # For 3D plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier  # used in Part 2 of Project 1\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define a simple Deep Neural Network (DNN) model\n",
        "class MyDNN(nn.Module):\n",
        "\n",
        "    # Constructor takes the number of input features\n",
        "    def __init__(self, input_dim):\n",
        "        super(MyDNN, self).__init__()  # Initialize the parent nn.Module\n",
        "        self.fc1 = nn.Linear(input_dim, 32)  # First fully connected layer (input_dim -> 32 units)\n",
        "        self.fc2 = nn.Linear(32, 32)  # Second fully connected layer (32 -> 32 units)\n",
        "        self.fc3 = nn.Linear(32, 1)  # Output layer (32 -> 1 unit, regression output)\n",
        "\n",
        "    # Defines forward pass\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))  # Apply ReLU activation to the first layer\n",
        "        x = F.relu(self.fc2(x))  # Apply ReLU activation to the second layer\n",
        "        x = self.fc3(x)          # Output layer (no activation for regression)\n",
        "        return x                 # Return the output of the third layer\n",
        "\n",
        "    # Predict\n",
        "    def predict(self, features):\n",
        "        \"\"\"\n",
        "        Predict function for inference.\n",
        "        Converts numpy features to torch tensor, performs forward pass, and returns numpy array.\n",
        "        \"\"\"\n",
        "        self.eval()  # Set model to evaluation mode (disables dropout, batchnorm, etc.)\n",
        "        features = torch.from_numpy(features).float()  # Convert numpy array to torch tensor\n",
        "        return self.forward(features).detach().numpy()  # Run forward pass, detach result, convert to nump\n",
        "\n",
        "class POSBCRobot(RobotPolicy):\n",
        "\n",
        "    def __init__(self, network):  # Constructor receives the neural network\n",
        "        if network is None:  # If network is not provided, create a new one\n",
        "            network = MyDNN(input_dim=4)  # Assuming 4 input features\n",
        "        self.network = network  # Store the neural network\n",
        "        self.learning_rate = 0.01  # Learning rate for optimizer\n",
        "        self.optimizer = torch.optim.SGD(self.network.parameters(), lr=self.learning_rate)  # SGD optimizer\n",
        "        self.criterion = nn.MSELoss()  # Mean Squared Error loss for regression\n",
        "        self.num_epochs = 500  # Number of training epochs\n",
        "        self.batchsize = 100  # Batch size for training\n",
        "        self.shuffle = True  # Shuffle data before each epoch\n",
        "\n",
        "    def train(self, data):\n",
        "        # Data\n",
        "        labels = data['obs']\n",
        "        features = data['actions']\n",
        "        print(f\"labels shape: {labels.shape}\")\n",
        "        print(f\"features shape: {features.shape}\")\n",
        "        #for key, val in data.items():\n",
        "            #print(key, val.shape)\n",
        "\n",
        "        # Training loop for multiple epochs\n",
        "        self.network.train()  # Set network to training mode\n",
        "        dataset = data(labels, features)  # Create dataset from labels and features\n",
        "        loader = DataLoader(dataset, shuffle=self.shuffle, batch_size=self.batchsize)  # DataLoader for batching\n",
        "        for epoch in range(self.num_epochs):  # Loop over epochs\n",
        "            self.train_epoch(loader)  # Train for one epoch\n",
        "\n",
        "    def train_epoch(self, loader):\n",
        "        # Train the network for a single epoch\n",
        "        total_loss = 0.0  # Track total loss for the epoch\n",
        "        for i, data in enumerate(loader):  # Loop over batches\n",
        "            features = data['feature'].float()  # Get features as float tensor\n",
        "            labels = data['label'].float()  # Get labels as float tensor\n",
        "            self.optimizer.zero_grad()  # Zero gradients before backpropagation\n",
        "            predictions = self.network(features)  # Forward pass to get predictions\n",
        "            loss = self.criterion(predictions, labels)  # Compute loss\n",
        "            loss.backward()  # Backpropagate the loss\n",
        "            total_loss += loss.item()  # Accumulate loss for reporting\n",
        "            self.optimizer.step()  # Update model parameters\n",
        "        print('loss', total_loss / i)  # Print average loss per batch after epoch\n",
        "\n",
        "    # Main function to run the entire pipeline\n",
        "    def main():\n",
        "        network = MyDNN(4)  # Neural network with four input features\n",
        "        trainer = train(network)   # Create a training manager for the network\n",
        "\n",
        "        features = np.asarray(features)   # Convert list to numpy array\n",
        "\n",
        "        labels = np.vectorize(function)(features [:, 0], features[:, 1].reshape(-1, 1)) # Compute labels using the true function for PyTorch\n",
        "\n",
        "        trainer.train(labels, features)  # Train the network on the data set\n",
        "\n",
        "\n",
        "    def get_action(self, obs):\n",
        "        return 0"
      ],
      "metadata": {
        "id": "ZH35w1j-Y7t3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation and Grading\n",
        "\n",
        "We will evaluate your model by simply having the agent follow the commands that it provides.  We will evaluate for 100 different randomly sampled starting positions and goals. For each goal, we roll out the trained policy for 50 steps. After the 50 steps, we will evaluate the closest distance to the goal the agent has ended up. If the agent reaches < 0.1 distance from the goal, the episode is ended before 50 steps and the minimum distance will be recorded as 0. The score is the fraction of the initial distance to goal covered by the agent averaged over 100 trials. Your final grade will be computed based on this score.\n",
        "\n",
        "We will calculate the score using the formula :\n",
        "\n",
        "```score = avg[(init_dist -  min_dist) / init_dist]```\n",
        "\n",
        "We will auto-generate your grades using the code below. The grading of each part is separate from each other so you can get the grade right after each part is finished.\n",
        "\n",
        "The total points of this assignment are 15. According to the difficulty level of each part, parts 1, 2, and 3 have 4, 5, 6 points respectively.\n",
        "\n",
        "- Part 1: if your score >= 0.99, you will receive 4 / 4. Otherwise, your final grade will be score / 0.99 * 4.\n",
        "- Part 2: if your score >= 0.95, you will receive 5 / 5. Otherwise, your final grade will be score / 0.95 * 5.\n",
        "- Part 3: if your score >= 0.95, you will receive 6 / 6. Otherwise, your final grade will be score / 0.95 * 6.\n",
        "\n",
        "The score function for each part provides two extra arguments to assist your debugging.\n",
        "\n",
        "- gui: If this is set to True, you will save the behavior of the agents during evaluation as an animation file. This animation file can be visualized using the provided code below to help you understand the behavior of the agent. **Please set it to False before your submission as it will slow down evaluation.**\n",
        "- model: If you provide a path to a saved model, the score function will not train from scratch but will instead load the save model. **Please set it to None before submission.** Any models you generate during runtime will be automatically deleted when disconnected. The grader will train the model from scratch."
      ],
      "metadata": {
        "id": "JLchnZGWZYeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE\n",
        "# Set up grading\n",
        "\n",
        "import score_policy\n",
        "import importlib\n",
        "importlib.reload(score_policy)\n",
        "from IPython.display import Image\n",
        "\n",
        "\n",
        "part1_bound = 0.99\n",
        "part2_bound = 0.95\n",
        "part3_bound = 0.95"
      ],
      "metadata": {
        "id": "ZporTBmpmahZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE\n",
        "# Getting the score and grade for Part 1\n",
        "\n",
        "score1 = score_policy.score_pos_bc(policy=POSBCRobot(), gui=True, model=None)\n",
        "grade1 = score1 / part1_bound * 4 if score1 < part1_bound else 4\n",
        "\n",
        "print('\\n---')\n",
        "print(f'Part 1 Score: {score1}')\n",
        "print(f'Part 1 Grade: {score1:.2f} / {part1_bound:.2f} * 4 = {grade1:.2f}')"
      ],
      "metadata": {
        "id": "-c-Ob4uUlRM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally, uncomment and run the code below if you have saved an animation (gui = True) that you want to visualize.\n",
        "\n",
        "Image(filename='part_1_anim.png', width=200, height=200)"
      ],
      "metadata": {
        "id": "Dx3AkUMamm4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part II. Behavioral cloning with visual observations\n",
        "\n",
        "In this part, you are asked to do a similar task as Part I, **but the observations will be RGB image observations of the world**, similar to the ones you used to do localization in Part III of Project 1. To process the RGB images, you will be implementing a CNN using PyTorch. [The official PyTorch tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) is a good starting point. As in Part I, the map that the robot is navigating is always the same. **This means that your model really only has to learn how to figure out where the robot and the goal are located, and how to navigate around a fixed set of obstacles.**\n",
        "\n",
        "All requirements from your code, as well as the evaluation method, are unchanged compared to Part I. The only difference is the nature of the observation that is provided to you."
      ],
      "metadata": {
        "id": "3s-mYCwfZql_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement your solution for Part 2 below\n",
        "\n",
        "\n",
        "class RGBBCRobot1(RobotPolicy):\n",
        "\n",
        "    def train(self, data):\n",
        "        for key, val in data.items():\n",
        "            print(key, val.shape)\n",
        "        print(\"Using dummy solution for RGBBCRobot1\")\n",
        "        pass\n",
        "\n",
        "    def get_action(self, obs):\n",
        "    \treturn 0"
      ],
      "metadata": {
        "id": "Y9VmDjXiagTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation and Grading"
      ],
      "metadata": {
        "id": "cj5Xje--lkiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE\n",
        "# Getting the score and grade for Part 2\n",
        "\n",
        "score2 = score_policy.score_rgb_bc1(policy=RGBBCRobot1(), gui=False, model=None)\n",
        "grade2 = score2 / part2_bound * 5 if score2 < part2_bound else 5\n",
        "\n",
        "print('\\n---')\n",
        "print(f'Part 2 Score: {score2}')\n",
        "print(f'Part 2 Grade: {score2:.2f} / {part2_bound:.2f} * 5 = {grade2:.2f}')"
      ],
      "metadata": {
        "id": "Y2kSdH99oESr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally, uncomment and run the code below if you have saved an animation (gui = True) that you want to visualize.\n",
        "\n",
        "# Image(filename='part_2_anim.png', width=200, height=200)"
      ],
      "metadata": {
        "id": "TauW8ur-mhOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part III. Behavioral cloning with visual observations - multiple maps\n",
        "\n",
        "This part is the same as  Part II except that it is trained and tested differently. **The training set involves expert demonstrations for the two new obstacle maps. And while testing, for each trial, a different obstacle map is randomly selected.** This means that your model has to learn how to reason about what an obstacle is, and how to go around it, based on nothing more than an image. The main objective of this part is to show that, when using a CNN, it is possible for a model to achieve this. The evaluation method for this part is the same as Part I and II."
      ],
      "metadata": {
        "id": "1I6v1TgCctRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement your solution for Part 3 below\n",
        "\n",
        "\n",
        "class RGBBCRobot2(RobotPolicy):\n",
        "\n",
        "    def train(self, data):\n",
        "        for key, val in data.items():\n",
        "            print(key, val.shape)\n",
        "        print(\"Using dummy solution for RGBBCRobot2\")\n",
        "        pass\n",
        "\n",
        "    def get_action(self, obs):\n",
        "    \treturn 0"
      ],
      "metadata": {
        "id": "AxQwN2MAdO09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation and Grading\n"
      ],
      "metadata": {
        "id": "aAky_Vu9l_EC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE\n",
        "# Getting the score and grade for Part 3\n",
        "\n",
        "score3 = score_policy.score_rgb_bc2(policy=RGBBCRobot2(), gui=False, model=None)\n",
        "grade3 = score3 / part3_bound * 6 if score3 < part3_bound else 6\n",
        "\n",
        "print('\\n---')\n",
        "print(f'Part 3 Score: {score3}')\n",
        "print(f'Part 3 Grade: {score3:.2f} / {part3_bound:.2f} * 6 = {grade3:.2f}')"
      ],
      "metadata": {
        "id": "PM4edyLqpT3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally, uncomment and run the code below if you have saved an animation (gui = True) that you want to visualize.\n",
        "\n",
        "# Image(filename='part_3_anim.png', width=200, height=200)"
      ],
      "metadata": {
        "id": "UmyAWRQwB2Rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Other Requirements and Hints\n",
        "\n",
        "- **Training time**: To keep auto-grading feasible, your total training time must be strictly under 3 mins, 15mins, and 10 mins for parts 1, 2, and 3. These time budgets are more than enough to achieve full credits on this project. Note that longer training time does not necessarily mean higher performance because of overfitting. The faster your network trains the better!\n",
        "- **Memory usage**: Make sure your code does not require too much memory. The required amount of RAM for this assignment should not be more than 8GB.\n",
        "- **NO GPU**: No GPU is required or allowed for this assignment.\n",
        "- **Reproducibility**: We have ensured that the randomness of the environment is deterministic. To get reproducible scores you must ensure your model training and prediction are also reproducible. The randomly initialized weights of the neural network should be made repeatable using seeding. You can add PyTorch seeding method below and see [PyTorch Reproducibility](https://pytorch.org/docs/stable/notes/randomness.html) to learn more.\n",
        "  ```\n",
        "  import torch\n",
        "  torch.manual_seed(0)\n",
        "  ```\n",
        "- **Classifier**: In all the parts we are training a neural network to solve a classification problem and it is important to use a reasonable loss function. For example, the MSE (mean squared classification) error has drawbacks related to sensitivity. Cross entropy loss usually has good performance for classification tasks and you can find the documentation for it [here](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss) and is further explained below. However, note that you are free to use any loss function you like.\n",
        "  - Cross entropy is a concept from information theory which is defined for two probability distributions. Cross entropy is minimum when the two distributions involved are the same and this is the property that makes it useful as a loss function in the context of machine learning. The idea is to minimize the cross entropy between the prediction distribution and the label distribution. For our case where we are training a neural network for classification, we can have the network output a score for each action. Cross entropy can be computed from these scores by converting to probability values (using softmax) and comparing it with the label distribution. The label distribution is obtained simply by assigning a probability of 1 to ground truth action and 0 to all other actions. Once trained, the best action can found by just choosing the action with the highest probability (i.e., the highest score) as predicted by the network.\n",
        "- **Optimizer**: While it is possible to use a simple optimizer to achieve the desired accuracy, the training time can be quite high. There exist a number of optimizers implemented in PyTorch that have much faster convergence.\n",
        "- **Parameter tuning**: Keep your architectures simple and slowly add complexity (more layers/kernels) to improve accuracy. Remember \"To Err is Human\" and the expert data (collected by a human) that you are training on is not perfect. Having a 100% training accuracy (very small training loss) might not be the best for achieving the highest score. So make sure your model does not overfit during training.\n",
        "- **PyTorch input shape**: Notice that the expected input shape to CONV2D in PyTorch is (N, C, H, W), where N is the batch size, C is the number of channels, H is the image height and W is the image width. You will need to switch axes for the incoming images in order for them to be correctly passed to the first convolution layer."
      ],
      "metadata": {
        "id": "bNJs1PcRpnSw"
      }
    }
  ]
}
